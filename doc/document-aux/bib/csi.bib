

@TechReport{	  abecassis.10.seminar,
  author	= {Felix Abecassis},
  title		= {Minimization of automata representing obligation
		  formulae},
  titre		= {Minimisation d'automates repr\'esentant des obligations},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  number	= 1004,
  url		= {http://publications.lrde.epita.fr/201004-Seminar-Abecassis}
		  ,
  urllrde	= {201004-Seminar-Abecassis},
  abstract	= {Model checking is a research field addressing the
		  automatic verification of the correctness of finite-state
		  systems towards a specification. Spot is a model checking
		  library based on an automata approach: the system is
		  translated into a transition-based generalized B\"uchi
		  automaton, the specifications are expressed as linear
		  temporal logic (LTL) formulae and then translated into a
		  B\"uchi automaton.\\ LTL formulae can be classified into a
		  hierarchy depending on the type of property they express.
		  We will study the case of LTL formulae representing
		  obligation properties. These can be recognized by a
		  restricted class of automata which have a computable
		  canonical minimal form.},
  resume	= {Le model checking est une discipline s'int\'eressant \`a
		  la v\'erification automatique de la conformit\'e d'un
		  syst\`eme fini vis-\`a-vis d'une propri\'et\'e. Spot est
		  une biblioth\`eque de model checking bas\'ee sur une
		  approche automate: le syst\`eme \`a v\'erifier est
		  repr\'esent\'e par un automate de B\"uchi g\'en\'eralis\'e
		  bas\'e sur les transitions, les propri\'et\'es sont
		  exprim\'ees par des formules de logique temporelle
		  lin\'eaire (LTL) et sont traduites en automate de
		  B\"uchi.\\ Les formules LTL peuvent \^etre class\'ees dans
		  une hi\'erarchie selon le type de propri\'et\'e qu'elles
		  repr\'esentent. Nous \'etudierons le cas des formules LTL
		  repr\'esentant des propri\'et\'es d'obligation, ces
		  formules peuvent \^etre reconnues par un type plus pr\'ecis
		  d'automates dont il est possible de calculer une forme minimale canonique.}
}

@TechReport{	  abecassis.11.seminar,
  author	= {Felix Abecassis},
  title		= {Optimizations in the Tiger Compiler},
  titre		= {Optimisations dans le compilateur Tiger},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  number	= 1103,
  url		= {http://publications.lrde.epita.fr/201107-Seminar-Abecassis}
		  ,
  urllrde	= {201107-Seminar-Abecassis},
  abstract	= {The Tiger Compiler is an educative project playing a
		  central role in EPITA's third year curriculum. This project
		  is the opportunity to teach students software engineering
		  practices such as design patterns, testing, documentation,
		  etc. As the age of serial computing is over,
		  parallel-computing technology that was once relegated to
		  universities and research labs is now a core requirement in
		  any computer science curriculum and thus we would like to
		  introduce parallelization in the project. In this report we
		  investigate the possibilities of parallelism in the Tiger
		  Compiler using the Intel Threading Building Blocks (TBB)
		  library. We also diagnosed and corrected several
		  performance problems in the register allocation
		  algorithm.},
  resume	= {Le compilateur Tiger est un projet \'educatif jouant un
		  r\^ole central dans le cursus de la troisi\`me ann\'ee de
		  l'EPITA. Ce projet est l'occasion d'enseigner aux
		  \'etudiants des bonnes pratiques de d\'eveloppement
		  logiciel comme les design patterns ainsi que l'importance
		  des tests et de la documentation. L'\`ere de l'informatique
		  s\'equentielle \'etant termin\'ee, la programmation
		  parall\`ele, autrefois relegu\'ee aux universit\'es et aux
		  laboratoires de recherche est maintenant devenue
		  incontournable dans tout cursus d'informatique, pour cette
		  raison nous aimerions introduire du parall\`elisme dans le
		  projet. Dans ce rapport nous \'etudions les possibilit\'es
		  de parall\'elisation dans le compilateur Tiger en utilisant
		  la biblioth\`eque Intel Threading Building Blocks (TBB).
		  Nous avons \'egalement diagnostiqu\'e et corrig\'e
		  plusieurs soucis de performance dans l'algorithme d'allocation de registres.}
}

@TechReport{abecassis.12.seminar,
  author =      {Felix Abecassis},
  title =       {Parallelization in a generic image processing library},
  titre =	{Parall\'{e}lisation dans une biblioth\`{e}que de traitement
                  d'images g\'{e}n\'{e}rique},
  abstract =	{Milena is an image processing library focused on
                  genericity: using advanced template meta-programming
                  techniques, algorithms are written once and can then
                  run on many types of images: 1D, 2D, 3D,
                  graph-based, built on a cell complex, etc.  In order
                  to improve the efficiency of the library we would
                  like to introduce optimization techniques offered by
                  modern processors: multicore parallelism and SIMD
                  (Single Instruction, Multiple Data)
                  vectorization. In this report we investigate how
                  such low-level constructs can be integrated while
                  preserving genericity.},
  resume =	{Milena est une biblioth\`{e}que de traitement d'images
                  focalis\'{e}e sur la g\'{e}n\'{e}ricit\'{e} : en utilisant des
                  techniques avanc\'{e}es de m\'{e}ta-programmation, les
                  algorithmes sont \'{e}crits une seule fois et peuvent
                  \^{e}tre ensuite ex\'{e}cut\'{e}s sur de nombreux types d'images
                  : 1D, 2D, 3D, sur une structure de graphe, sur un
                  complexe cellulaire, etc.  Afin d'am\'{e}liorer les
                  performances, nous souhaitons introduire des
                  techniques d'optimisation rendues possibles par les
                  fonctionnalit\'{e}s des processeurs r\'{e}cents:
                  parall\'{e}lisme multi-c\oe{}ur et vectorisation SIMD
                  (Single Instruction, Multiple Data). Dans ce rapport
                  nous \'{e}tudions comment de telles fonctionnalit\'{e}s, \`{a}
                  l'origine bas niveau, peuvent \^{e}tre int\'{e}gr\'{e}es tout en
                  pr\'{e}servant la g\'{e}n\'{e}ricit\'{e}.},
  institution = {EPITA Research and Development Laboratory (LRDE)},
  year =        2012,
  number =	1117,
  url =         {http://publications.lrde.epita.fr/201201-Seminar-Abecassis}},
  urllrde =     {201201-Seminar-Abecassis,
}


@TechReport{	  abraham.07.seminar,
  oldkeys	= {abraham.07.seminar.conceptgcc},
  author	= {Alexandre Abraham},
  title		= {{ConceptC++} study and possible integration in {SCOOP}},
  titre		= {Etude de {ConceptC++} et possible int\'egration dans
		  {SCOOP}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  number	= 0748,
  url		= {http://publications.lrde.epita.fr/200706-Seminar-Abraham},
  urllrde	= {200706-Seminar-Abraham},
  abstract	= {At the end of this decade will arise C++0x and with it the
		  new ``concept'' paradigm. Concepts provide abstract types
		  as well as all the equipment to adapt concrete types to
		  their abstraction, just like \emph{Static} library, a part
		  of Olena project, does.\\ We compare these two approaches,
		  highlighting their respective strengths and weaknesses, in
		  order to lay the foundations for the integration of
		  concepts into SCOOP. In fact, concepts will simplify the
		  client code and bring some new features to SCOOP.},
  resume	= {La fin de cette d\'ecennie verra l'av\`enement de C++0x et
		  avec lui du nouveau paradigme de \og concepts \fg{}. Les
		  concepts fournissent un m\'ecanisme de typage abstrait pour
		  les types param\'etr\'es ainsi que tout l'\'equipement
		  d'adaptation des types concrets \`a ces types abstraits
		  comme le fait actuellement la biblioth\`eque \emph{Static},
		  composant du projet Olena.\\ Nous proposons donc un
		  comparatif de ces approches en exhibant leurs points forts
		  et faibles ainsi que leurs capacit\'es particuli\`eres afin
		  de proposer un support de documentation et une base pour la
		  future int\'egration des concepts dans le paradigme SCOOP.
		  Les concepts simplifieront l'\'ecriture du code client et
		  enrichiront SCOOP de fonctions suppl\'ementaires.}
}

@TechReport{	  abraham.08.seminar,
  author	= {Alexandre Abraham},
  title		= {Topological Watershed},
  titre		= {Ligne de partage des eaux topologique},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200806-Seminar-Abraham},
  urllrde	= {200806-Seminar-Abraham},
  abstract	= {Dividing a picture into area of interest is called picture
		  segmentation, it is useful in particular to point out
		  cancerous cells in medical imaging. The \emph{Watershed
		  Transform} provides such a segementation and can be
		  implemented in many ways. Here we will focus on the \emph{
		  Topological Watershed}, a performant algorithm producing
		  results with nice properties. In this report, we will show
		  how this algorithm had been implemented in Milena, the C++
		  generic image processing library of Olena, developed at the
		  LRDE. We will first see how to treat usual image format and
		  then generalize it to trickier formats like pictures mapped
		  on general graphs.},
  resume	= {Segmenter une image consiste \`a en extraire les r\'egions
		  d'int\'er\^et, par exemple pour s\'eparer des cellules
		  canc\'ereuses en imagerie m\'edicale. L'approche par
		  transformation de la ligne de partage des eaux (LPE) ou
		  \emph{Watershed Transform} permet d'obtenir une telle
		  segmentation. Il en existe de nombreuses d\'efinitions,
		  ainsi que diverses impl\'ementations, dont certaines sont
		  \`a la fois performantes et produisent un r\'esultat avec
		  de bonnes propri\'et\'es, comme le \emph{Topological
		  Watershed}. Cet expos\'e pr\'esentera l'impl\'ementation
		  d'un algorithme calculant cette LPE au sein de Milena, la
		  biblioth\`eque C++ g\'en\'erique de traitement d'image de
		  la plate-forme Olena, d\'evelopp\'ee au LRDE. Nous nous
		  int\'eresserons tout d'abord aux formats d'images
		  ``classiques'', puis \`a la g\'en\'eralisation \`a des
		  formats d'images plus inhabituels (images \`a support de graphe g\'en\'eraux, etc.).},
  number	= 0821
}

@TechReport{	  abraham.09.seminar,
  author	= {Alexandre Abraham},
  title		= {Morphology on color images},
  titre		= {Morphologie sur images couleur},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  url		= {http://publications.lrde.epita.fr/200901-Seminar-Abraham},
  urllrde	= {200901-Seminar-Abraham},
  abstract	= {This work takes place in the context of Milena, the C++
		  generic image processing library of the Olena platform,
		  developed at LRDE. Morphological algorithms are one of
		  Milena's major assets. Yet few image processing libraries
		  implement them even though they are very useful. Those
		  algorithms require supremum and infimum operators, which
		  don't exist by default for composite types like
		  red-green-blue (RGB) pixels. We therefore propose the
		  implementation of those operators for RGB values, along
		  with a complete toolchain allowing morphological algorithms
		  to work on color images.},
  resume	= {Les algorithmes morphologiques sont l'un des atouts
		  majeurs de Milena, la biblioth\`eque de traitement d'image
		  g\'en\'erique et performante d\'evelopp\'ee au LRDE. En
		  effet, ils sont tr\`es utiles et relativement peu
		  impl\'ement\'es dans les autres biblioth\`eques. Ces
		  algorithmes requi\`erent des op\'erateurs de bornes
		  sup\'erieure et inf\'erieure (\emph{supremum} et
		  \emph{infimum}) qui n'existent pas par d\'efaut pour des
		  types composites comme les couleurs encod\'ees en
		  rouge-vert-bleu (RVB). Nous pr\'esentons donc une
		  impl\'ementation de ces op\'erateurs pour le type RVB ainsi
		  que toute la cha\^ine de traitement permettant de faire
		  fonctionner des algorithmes morphologiques sur des images en couleurs.},
  number	= 0835
}

@TechReport{	  anisko.03.seminar,
  oldkeys	= {trans-tech-rep,anisko.03},
  title		= {Transformers: a {C++} program transformation framework},
  author	= {Robert Anisko and Valentin David and Cl\'ement Vasseur},
  institution	= {LRDE},
  year		= 2003,
  number	= 0310,
  urllrde	= {20030521-Seminar-ClementVasseur-Transformers-Report}
}

@TechReport{	  badie.11.seminar,
  author	= {Thomas Badie},
  title		= {Simulation-based Reductions on TGBA},
  titre		= {R\'eduction bas\'ees sur la bisimulation appliqu\'ees aux
		  TGBA},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  abstract	= {Spot is a C++ library that relies on the automata
		  theoretic approach to model checking. To represent
		  properties we use LTL-formulae, which are translated into
		  automata. In Spot these automata are Transition-based
		  Generalized B\"uchi Automata (TGBA). A major issue for a
		  model checker is to be fast. A good way to reach that is to
		  make automata as small as possible. Scientific litterature
		  proposes a lot of algorithm to achieve our goal.
		  Bisimulation and simulation work on
		  $\mathcal{\omega}$-automata. We see in this report how to
		  adapt these algorithms to make them work on TGBA. We will
		  see the profit which is given by the bisimulation
		  implementation. And we deduce the importance to implement
		  the simulation to reduce TGBA. },
  resume	= {Spot est une biblioth\`eque C++ de model checking
		  utilisant l'approche par automates. Pour repr\'esenter les
		  propri\'et\'es \`a v\'erifier, nous utilisons des formules
		  LTL, qui sont traduites en automates. Dans Spot, ces
		  automates sont des Automates de B\"uchi g\'en\'eralis\'es
		  bas\'es sur les transitions (TGBA). Un enjeu pour tout
		  model checker, est d'\^etre rapide. Une mani\'ere de faire
		  est de rendre les automates aussi petit que possible. La
		  litt\'erature scientifique propose de nombreux algorithmes
		  pour arriver \`a notre but. La bisimulation et la
		  simulation r\'eduisent des automates qui reconnaissent des
		  mots de longueur infinis. Cette pr\'esentation montre
		  comment adapter ces algorithmes pour des TGBA ainsi que le
		  gain apport\'e par l'impl\'ementation de la bisimulation,
		  ce qui souligne l'importance d'impl\'ementer la simulation
		  pour r\'eduire les TGBA.},
  number	= 1104
}

@TechReport{	  ballas.07.seminar,
  oldkeys	= {ballas.07.seminar.olena.core},
  author	= {Nicolas Ballas},
  title		= {Software engineering in {O}lena {C}ore},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200706-Seminar-Ballas},
  urllrde	= {200706-Seminar-Ballas},
  abstract	= {Software engineering defines some methods in order to
		  guarantee software quality. In the image processing field,
		  several image types exist. Also, this is difficult to build
		  a library dedicated to this field which provides reusable,
		  extensible or compatible tools. We will see different
		  approaches used by generic image processing libraries which
		  deal with this problem.},
  number	= 0746
}

@TechReport{	  ballas.08.seminar,
  author	= {Nicolas Ballas},
  title		= {Image taxonomy in {M}ilena},
  titre		= {Taxonomie des images de {M}ilena},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200806-Seminar-Ballas},
  urllrde	= {200806-Seminar-Ballas},
  abstract	= {Milena is the generic image processing library of the
		  Olena platform. The library aims at remaining simple while
		  providing high performances. The introduction of new image
		  types based on graphs has revealed some design problems
		  limit ing its genericity. For instance, we have always
		  considered that "images have points"; yet some images have
		  sites that are not points (but edges, facets, and even sets
		  of points). Another erroneous assumption was to consider
		  that sites are localized by a vector (e.g., (x,y) in the 2D
		  plane), which cannot be true when sites are not point-wise.
		  Therefore there was a need to reconsider the image types
		  and their underlying images properties.In this seminar, we
		  will present a new image taxonomy that solves those
		  issues.},
  resume	= {Milena est la biblioth\`eque de traitement d'image
		  g\'en\'erique de la plate-forme Olena. Cette biblioth\`eque
		  a pour but d'\^etre performante tout en restant simple.
		  L'introduction dans Milena de nouveaux types d'images
		  bas\'es sur des graphes a mis en \'evidence des probl\`emes
		  de mod\'elisation qui sont un frein pour sa
		  g\'en\'ericit\'e. Par exemple, nous avons toujours
		  consid\'er\'e que "les images ont des points". N\'eanmoins,
		  certains types d'images poss\`edent des sites qui ne sont
		  pas des points (mais des arr\^etes, faces, ou m\^eme des
		  ensembles de points). Une autre supposition erron\'ee
		  \'etait de consid\'erer que les sites \'etaient toujours
		  localis\'es par un vecteur (c\`ad, (x,y) dans le plan 2D).
		  Cette supposition est fausse lorsque l'on manipule des
		  sites qui ne sont pas "Pointwise". Il etait donc
		  n\'ecessaire de modifier les types d'images utilis\'es dans
		  Milena et les propri\'et\'es qui leur sont associ\'ees.
		  Pendant ce s\'eminaire, nous pr\'esenterons une nouvelle
		  classification d'images permettant de r\'esoudre ces probl\`emes.},
  number	= 0812
}

@TechReport{	  ballas.09.seminar,
  author	= {Nicolas Ballas},
  title		= {Properties in {M}ilena},
  titre		= {Les propri\'et\'es dans {M}ilena},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  url		= {http://publications.lrde.epita.fr/200901-Seminar-Ballas},
  urllrde	= {200901-Seminar-Ballas},
  abstract	= {Getting both high performance and genericity at the same
		  time is one of the major research field at the LRDE.
		  Milena, the Olena platform library, faces that issue in the
		  context of image processing. Furthermore Milena has for
		  extra objective to remain simple to use for a practitioner.
		  A solution, experimented since several years, is based on
		  properties. Properties are a set of features statically
		  bound to a type. For instance, image types in Milena have a
		  property named speed that gives information at compile time
		  about the value access time. In this seminar, we focus on
		  the image properties. We detail the definition of those
		  properties and justify them. We show how those properties
		  help in improving efficiency while maintaining genericity.
		  For that, we take as illustration the implementation of low
		  level routines in the library.},
  resume	= {Avoir de hautes performances tout en conservant la
		  g\'en\'ericit\'e est un des domaines de recherche
		  pr\'epond\'erant au sein du LRDE. Milena, la biblioth\`eque
		  de la plate-forme Olena, confronte ce probl\`eme au domaine
		  du traitement d'image. De plus, Milena a aussi pour
		  objectif de rester simple \`a utiliser. Une solution \`a
		  ces probl\`emes, utilis\'ee depuis plusieurs ann\'ees,
		  repose sur les propri\'et\'es. Les propri\'et\'es sont un
		  ensemble de caract\'eristiques associ\'ees statiquement \`a
		  un type particulier. Par exemple, les types d'images de
		  Milena poss\`edent une propri\'et\'e speed qui indique les
		  temps d'acc\`es aux valeurs des images. Durant ce
		  s\'eminaire, nous nous int\'eresserons aux propri\'et\'es
		  des types d'images. Nous d\'etaillerons les d\'efinitions
		  de ces propri\'et\'ees. Nous montrerons aussi comment les
		  propri\'et\'es aident \`a am\'eliorer les performances tout
		  en maintenant la g\'en\'ericit\'e. Pour cela, nous
		  prendrons en illustration l'impl\'ementation des routines bas niveau dans la biblioth\`eque.},
  number	= 0829
}

@TechReport{	  bensalem.11.seminar,
  author	= {Ala-Eddine Ben-Salem},
  titre		= {Model Checking LTL utilisant des automates Testeurs},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  urllrde	= {2011-Seminar-Bensalem},
  year		= 2011,
  resume	= {Spot est une biblioth\`eque C++ de model checking bas\'ee
		  sur l'approche automate, et utilisant des automates de
		  B\"uchi. Le probl\`eme principal de cette approche est
		  l'explosion de l'espace d'\'etats \`a explorer. Afin de
		  r\'eduire la taille des automates repr\'esentant l'espace
		  d'\'etats, nous avons impl\'ement\'e dans Spot une solution
		  qui utilise des automates Testeurs \`a la place des
		  automates de B\"uchi. Nous pr\'esenterons les diff\'erentes
		  \'etapes de construction d'un automate Testeur \`a partir
		  d'un automate de B\"uchi. Ensuite, nous d\'etaillerons les
		  algorithmes de v\'erification manipulant des automates Testeurs. }
}

@TechReport{	  berger.05.seminar,
  author	= {Christophe Berger and Nicolas Widynski},
  title		= {Using connected operators to manipulate image components},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  urllrde	= {200507-Seminar-Berger-Widynski},
  year		= 2005,
  abstract	= {Connected operators are morphological filters which have
		  the property of keeping objects contours when simplifying
		  images. They bring to the light objects situated in the
		  image. To do it, an implementation of the Tarjan's
		  Union-find algorithm is used for an easy manipulation of
		  image components. A binary partition tree is built, in
		  order to simplify the objects attributes computation and
		  the filtering of image. First of all, we will introduce
		  morphological filters and connected operators, then we will
		  propose an overview of different kinds of methods used in
		  the literature in order to create a binary partition tree
		  and we will explain the Tarjan's "union-find" algorithm for
		  the image filtering. At last, we will apply this method in
		  order to clean and delete stars in space's images.},
  number	= 0517
}

@TechReport{	  berger.06.seminar,
  oldkeys	= {berger.06.seminar.taxonomy},
  author	= {Christophe Berger},
  title		= {Image taxonomy in {O}lena},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  urllrde	= {200605-Seminar-Berger},
  year		= 2006,
  number	= 0603
}

@TechReport{	  bigaignon.05.seminar,
  oldkeys	= {bigaignon.aut-to-exp.05.seminar},
  author	= {Robert Bigaignon},
  title		= {Computing the regular language recognized by a finite
		  automaton},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2005,
  urllrde	= {200506-Seminar-Bigaignon},
  number	= 0508
}

@TechReport{	  cadilhac.05.seminar,
  oldkeys	= {cadilhac.cover-automata.05.seminar},
  author	= {Micha\"el Cadilhac},
  title		= {Cover automata for finite languages},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2005,
  urllrde	= {20050622-Seminar-Cadilhac-CoverAutomata-Report},
  number	= 0504
}

@TechReport{	  carlinet.09.seminar,
  author	= {Edwin Carlinet},
  titre		= {Les arbres de composantes dans Milena},
  title		= {Component trees in Milena},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  urllrde	= {200906-Seminar-Carlinet},
  url		= {http://publications.lrde.epita.fr/200906-Seminar-Carlinet}
		  ,
  abstract	= {Pattern recognition and object detection are very
		  important stakes in image processing. Many solutions have
		  been provided; nevertheless the one based on component
		  trees seems to be the most promising. A component tree
		  allows to work on connected components at different
		  gray-levels in the image. Thanks to this tree, we can use
		  attributes as criteria to identify components, such a
		  component being an object in the image. During this
		  seminar, we present a component tree implementation, how to
		  deal with attributes, different methods dedicated to
		  component identification and a general processing chain
		  that leads to object recognition. },
  resume	= {La d\'etection des formes et la reconnaissance d'objets
		  font partie des enjeux les plus importants du traitement
		  d'images. Diff\'erentes strat\'egies ont d\'ej\`a vu le
		  jour; n\'eanmoins celle bas\'ee sur l'utilisation des
		  arbres de composantes semble particuli\`erement
		  prometteuse. En effet, l'arbre de composantes permet
		  d'\'etablir puis de mettre en relation les composantes \`a
		  diff\'erents niveaux de gris de l'image. \`A partir de cet
		  arbre, il devient alors possible d'appliquer des attributs
		  qui serviront de crit\`eres pour filtrer ces composantes et
		  mettre en \'evidence les objets de l'image. Nous
		  pr\'esenterons donc l'impl\'ementation de ces arbres,
		  l'utilisation des attributs et des politiques de
		  propagation pour filtrer les composantes, ainsi que la
		  cha\^ine de traitement qui permettra d'identifier ces objets. },
  number	= 0910
}

@TechReport{	  carlinet.10.seminar,
  author	= {Edwin Carlinet},
  titre		= {Filtrage \`a base de contours pour la segmentation
		  d'images},
  title		= {An edge-based attribute filter dedicated to image
		  segmentation},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  urllrde	= {201006-Seminar-Carlinet},
  url		= {http://publications.lrde.epita.fr/201006-Seminar-Carlinet}
		  ,
  abstract	= {We propose a new edge-based method dedicated to image
		  segmentation. The last few years have shown the development
		  of image processing with connected filters. Indeed,
		  contour-preserving properties of connected operators are
		  highly desired for image segmentation. The connected
		  operators-based segmentation methods usually proceed in two
		  steps. They first compute an attribute on the connected
		  components and filter the components of which attribute do
		  not satisfy a criterion. In these methods, attributes are
		  actually computed on the pixels of connected components. We
		  propose a new union-find based algorithm that enables
		  evaluation of attributes on connected component edges so
		  that we can finally compute an attribute on their contours.
		  We therefore introduce edges-based attributes and propose
		  some of them that evaluate a connected components energy.
		  We finally perform an edge-based attribute filtering to
		  produce a new image segmentation method.},
  resume	= {Les dernieres ann\'ees ont \'et\'e marqu\'ees par le
		  d\'eveloppement des techniques de segmentation \`a base de
		  filtres connect\'es. Ces m\'ethodes proc\`edent
		  g\'en\'eralement en deux \'etapes. Elles calculent un
		  attribut sur les composantes connect\'ees puis filtrent
		  celles qui ne satisfont pas un certain crit\`ere. Nous
		  proposons un nouvel algorithme bas\'e sur l'union-find qui
		  permet de calculer des attributs directement sur les
		  contours des composantes connect\'ees et d' en \'etudier
		  leur energie. Nous introduisons ainsi le filtrage \`a base
		  de contours dans une nouvelle m\'ethode de segmentation.},
  number	= 1005
}

@TechReport{	  carlinet.11.seminar,
  author	= {Edwin Carlinet},
  titre		= {Un algorithme rapide pour l'arbre auto-dual},
  title		= {A fast algorithm for auto-dual trees},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  urllrde	= {201006-Seminar-Carlinet},
  url		= {http://publications.lrde.epita.fr/201006-Seminar-Carlinet}
		  ,
  abstract	= {For the last few years, connected operators have gained a
		  certain popularity in image processing field, they have
		  been widely used for filtering, image segmentation, object
		  detection\ldots However, they encountered several issues,
		  the most important being \textit{contrast dependence}, one
		  can only retrieve either dark or bright objects. Auto-dual
		  operators allow computation on dark and bright components
		  in the same time and as a consequence, do not suffer from
		  the drawback of classical connected operators. However,
		  auto-dual operators are more difficult to implement and
		  current algorithms are computationally expensive. We
		  propose a new algorithm to compute auto-dual operators
		  based on Tarjan's union-find which is faster that current
		  state-of-the-art contour tree algorithms.},
  resume	= {Ces derni\`eres ann\'ees, les op\'erateurs connect\'es ont
		  gagn\'e une certaine popularit\'e dans le domaine du
		  traitement d'images, ils ont en effet \'et\'e largement
		  utilis\'es dans le cadre de filtrage, de segmentation, de
		  d\'etection d'objets\ldots N\'eanmoins, plusieurs d\'efauts
		  ont \'et\'e mis en \'evidence, le plus important \'etant
		  \textit{la d\'ependance au contraste}, on ne peut que
		  d\'etecter soit les objets clairs, soit les objets
		  fonc\'es. Les op\'erateurs auto-duaux permettent d'op\'erer
		  sur les objets clairs et fonc\'es \`a la fois et ne
		  souffrent donc pas du d\'efaut des op\'erateurs connect\'es
		  classiques. En revanche, les op\'erateurs auto-duaux sont
		  plus difficiles \`a mettre en place et les algorithmes
		  actuellement disponibles sont co\^uteux en temps de calcul.
		  Nous proposons un nouvel algorithme pour calculer les
		  op\'erateurs auto-duaux bas\'es sur l'union-find de Tarjan;
		  celui-ci offrant de meilleures performances que
		  l'algorithme d'arbre de contours \`a l'\'etat de l'art.}
}

@TechReport{	  charron.08.seminar,
  author	= {Samuel Charron},
  title		= {Homolib},
  titre		= {Homolib},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/20080901-Seminar-Charron}
		  ,
  urllrde	= {20080901-Seminar-Charron},
  abstract	= {Decision Diagrams are a family of data structures that
		  represents huge data sets using a small amount of memory.
		  These structures can be of fixed size (tuples), or varying
		  size (lists, maps, ...), the DD handling being different
		  for each one. Data Decision Diagrams and Set Decision
		  Diagrams handle varying size data thanks to operations
		  named homomorphisms. However, the definition of a correct
		  operation can be hard because numerous errors hard to
		  identify can happen. This seminar offers a presentation of
		  an algorithms library that gives a more abstract view on
		  handled data. This library contains the algorithms defined
		  in "List" and "Map" modules from the Objective Caml
		  standard library, allowing the user to focus on his
		  specific problem.},
  resume	= {Les Diagrammes de D\'ecision sont une famille de
		  structures de donn\'ees permettant de repr\'esenter avec
		  peu de m\'emoire de grands ensembles de donn\'ees. Ces
		  structures peuvent \^etre de taille fixe (un tuple) ou
		  variable (une liste, un conteneur associatif, \ldots), la
		  manipulation du DD ne se faisant pas de la m\^eme
		  mani\`ere. Les Data Decision Diagrams et Set Decision
		  Diagrams manipulent des donn\'ees de taille variable
		  gr\^ace \`a des op\'erations, les homomorphismes. Cependant
		  la d\'efinition d'une op\'eration correcte peut d\'erouter
		  l'utilisateur, et passe souvent par de nombreuses erreurs,
		  difficiles identifier. Ce s\'eminaire propose une
		  biblioth\`eque d\`ualgorithmes fournissant une vue plus
		  abstraite que les homomorphismes "bruts" des donn\'ees
		  manipul\'ees, en reprenant les algorithmes d\'efinis dans
		  les modules "List" et "Map" d'Objective Caml. L'utilisateur
		  peut se concentrer sur les parties sp\'ecifiques \`a son probl\`eme.},
  number	= 0760
}

@TechReport{	  chedeau.10.seminar,
  author	= {Christopher Chedeau},
  title		= {Functionnal approach of image processing genericity},
  titre		= {Approche fonctionnelle de la g\'en\'ericit\'e du
		  traitement d'image},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  url		= {http://publications.lrde.epita.fr/201004-Seminar-Chedeau},
  urllrde	= {201004-Seminar-Chedeau},
  abstract	= {Olena is one of the most advanced image processing
		  libraries in terms of genericity. It mainly comes from a
		  different vision of the image notion composed of key
		  concepts such as Windows, Accumulators, Dispatch by Traits
		  and Morphers. We make a detailed description and explain
		  how to implement them within Lisp.},
  resume	= {Olena est l'une des biblioth\`eques de traitement d'images
		  dont la g\'en\'ericit\'e est la plus pouss\'ee. Celle-ci
		  vient principalement d'une vision diff\'erente de la notion
		  d'image via des concepts cl\'es tels que les fen\^etres,
		  accumulateurs, dispatch par traits ainsi que les morphers.
		  On va s'attacher \`a en faire une description d\'etaill\'ee
		  ainsi que montrer comment les impl\'ementer en Lisp.},
  number	= 1001
}

@TechReport{	  chedeau.11.seminar,
  author	= {Christopher Chedeau},
  title		= {Component Trees and Chaining Operators in Climb},
  titre		= {Arbres de composantes et op\'erateurs de cha\^inage},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  url		= {http://publications.lrde.epita.fr/201107-Seminar-Chedeau},
  urllrde	= {201107-Seminar-Chedeau},
  abstract	= {Climb is a generic image processing library designed to be
		  used for rapid prototyping. The implementation of two
		  component trees algorithms impacts Climb in several ways:
		  the definition of values is extended, new site sets are
		  added and debugging utilities are improved. \\ A detour is
		  taken to understand the Chaining design pattern popularized
		  by the Javascript jQuery library. The pattern is adapted to
		  both the image processing domain and Common Lisp and is
		  extended to introduce a parallel notation as well as better
		  control flows.},
  resume	= {Climb est une biblioth\`eque de traitement d'images
		  g\'en\'erique ayant pour objectif le prototypage rapide.
		  L'impl\'ementation de deux algorithmes d'arbre de
		  composantes impacte Climb de plusieurs fa\c{c}ons : la
		  d\'efinition des valeurs est \'etendue, de nouveaux
		  ensembles de sites sont ajout\'es et les outils de
		  d\'eveloppement sont am\'elior\'es. \\ Un d\'etour est pris
		  afin de comprendre le patron de conception de cha\^inage
		  popularis\'e par la biblioth\`eque jQuery. La m\'ethode est
		  modifi\'ee afin de s'adapter au traitement d'images ainsi
		  qu'\`a Common Lisp. Elle est \'egalement \'etendue via une
		  notation parall\`ele ainsi qu'avec une meilleure gestion du fil d'ex\'ecution.},
  number	= 1108
}

@TechReport{	  claveirole.04.seminar.analysis,
  oldkeys	= {claveirole.vcsn-analysis.04},
  author	= {Thomas Claveirole},
  title		= {Analysis of the {V}aucanson project},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2004,
  urllrde	= {20040526-Seminar-Claveirole-Vaucanson_Analysis-Slides}
}

@TechReport{	  claveirole.04.seminar.overview,
  oldkeys	= {claveirole.vcsn-overview.04},
  author	= {Thomas Claveirole},
  title		= {An overview of {V}aucanson},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2004,
  urllrde	= {20041124-Seminar-Claveirole-VaucansonOverview-Report},
  number	= 0401
}

@TechReport{	  d-halluin.08.seminar,
  author	= {Florent D'Halluin},
  title		= {{Y}et {A}nother {V}aucanson {GUI}},
  titre		= {Interface graphique de {V}aucanson},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  abstract	= {Vaucanson is a finite state machine manipulation platform.
		  Since it was started in 2002, the project has been
		  attracting more and more users. In that regard, it requires
		  an efficient user front end.\par For non-expert users,
		  automaton manipulation can be done via taf-kit, a set of
		  command-line tools. A first GUI was developed in 2005. Its
		  use was slow and complicated since it relied on taf-kit for
		  every operation.\par This new GUI, plugged directly into
		  the core of the Vaucanson library for efficiency,
		  simplifies the automaton manipulation process and makes
		  full use of the generic algorithms included in the library.},
  resume	= {Vaucanson est une plateforme de manipulation d'automates
		  finis. D\'ebut\'e en 2002, le projet attire de plus en plus
		  d'utilisateurs. De ce fait, une interface utilisateur
		  efficace est n\'ecessaire.\par Pour l'utilisateur non
		  expert, la manipulation d'automates peut s'effectuer via
		  taf-kit, une suite d'outils accessible en ligne de
		  commande. Une premi\`ere interface graphique avait \'et\'e
		  esquiss\'ee en 2005, mais son fonctionnement \'etait lent
		  et compliqu\'e car elle s'appuyait sur taf-kit pour
		  r\'ealiser chaque op\'eration.\par Cette nouvelle interface
		  graphique, branch\'ee directement sur le c\oe{}ur de la
		  biblioth\`eque pour plus d'efficacit\'e, simplifie la
		  manipulation d'automates et rend accessible les algorithmes
		  g\'en\'eriques de Vaucanson.},
  url		= {http://publis.lrde.epita.fr/200807-Seminar-DHalluin},
  urllrde	= {200807-Seminar-DHalluin},
  number	= 0822
}

@TechReport{	  d-halluin.09.seminar,
  author	= {Florent D'Halluin},
  title		= {Benchmarking {V}aucanson and large {C++} libraries},
  titre		= {Analyse de performances dans {V}aucanson},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  abstract	= {Vaucanson is an extensive C++ library for the manipulation
		  of finite state machines. Compared to its main competitor,
		  OpenFST, Vaucanson has major performance issues. In order
		  to improve the performance of Vaucanson, a set of tools is
		  required to analyze the library's behavior in terms of CPU
		  time requirements and memory usage. Up to March 2009, no
		  existing tool was fully adapted to Vaucanson and practical
		  to use. CBS is a C++ Benchmarking Suite that measures the
		  performance of C++ projects and provides tools to display,
		  analyze and compare results in a human-readable form. It is
		  used for in-depth Vaucanson profiling, and it helps the
		  development team rewrite algorithms.},
  resume	= {Vaucanson est une biblioth\`eque C++ de manipulation
		  d'automates finis. Par rapport \`a son concurrent
		  principal, OpenFST, Vaucanson souffre d'importants
		  probl\`emes de performances. Afin d'am\'eliorer les
		  performances de Vaucanson, il est n\'ecessaire d'avoir des
		  outils appropri\'es pour analyser le comportement de la
		  biblioth\`eque en termes d'utilisation de temps CPU et de
		  gestion de la m\'emoire. Jusqu'en Mars 2009, il n'existait
		  pas d'outils de ce type pratiques \`a utiliser avec
		  Vaucanson. CBS (C++ Benchmarking Suite) est une suite
		  d'outils d'analyse de performances pour projets C++. Ces
		  outils permettent de mesurer, d'afficher, et de comparer
		  l'utilisation de ressources (temps, m\'emoire), dans un
		  format accessible \`a l'utilisateur. Ils sont utilis\'es
		  pour analyser Vaucanson afin de r\'e\'ecrire les
		  algorithmes les moins efficaces.},
  url		= {http://publis.lrde.epita.fr/200905-Seminar-DHalluin},
  urllrde	= {200905-Seminar-DHalluin},
  number	= 0902
}

@TechReport{	  d-halluin.10.seminar,
  author	= {Florent D'Halluin},
  title		= {Adapting {V}aucanson algorithms to a simpler interface},
  titre		= {Adaptation d'algorithmes de {V}aucanson \`a une interface
		  plus simple},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  abstract	= {Vaucanson is an extensive C++ library for the manipulation
		  of finite state machines. User feedback shows that
		  Vaucanson is slow and that the library interface for direct
		  automaton manipulation is complex. To enhance Vaucanson,
		  the development team is making major changes to simplify
		  the interface over the Automata data structure and
		  reinstate a sane modeling for the underlying
		  implementation. A consequence of these changes is that the
		  algorithms available in the Vaucanson library must be
		  adapted to the new interface. Adapting algorithms is an
		  opportunity to study the impact of the recent interface and
		  implementation changes on performance and accessibility.
		  Because the new interface over automata is simpler,
		  possible optimizations are more apparent.},
  resume	= {Vaucanson est une biblioth\`eque C++ de manipulation
		  d'automates finis. Le feedback utilisateur montre que
		  Vaucanson est lent et que l'interface de la biblioth\`eque
		  qui permet de manipuler les automates directement est
		  complexe. Pour am\'eliorer Vaucanson, l'\'equipe de
		  d\'eveloppement met en place une interface simplifi\'ee sur
		  la structure de donn\'ees Automata et r\'einstaure une
		  mod\'elisation saine de l'impl\'ementation sous-jacente.
		  Une cons\'equence de ces changements est que les
		  algorithmes disponibles dans Vaucanson doivent \^etre
		  adapt\'es \`a la nouvelle interface. L'adaptation de ces
		  algorithmes donne l'opportunit\'e d'\'etudier l'impact des
		  changements r\'ecents sur les performances et
		  l'accessibilit\'e de Vaucanson. Gr\^ace \`a la simplicit\'e
		  de la nouvelle interface, les optimisations possibles
		  deviennent plus visibles. },
  url		= {http://publis.lrde.epita.fr/201001-Seminar-DHalluin},
  urllrde	= {201001-Seminar-DHalluin},
  number	= 0914
}

@TechReport{	  damota.09.seminar,
  author	= {Samuel Da Mota},
  title		= {Nondeterminisation of alternating automata in SPOT},
  titre		= {Nond\'eterminisation d'automates alternants dans SPOT},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  abstract	= {SPOT is a C++ model checking library that relies on the
		  automata theoretic approach to model checking. The first
		  step of this approach consists in the translation of an LTL
		  formula to an automaton that recognizes the same language.
		  Currently, there exists two algorithms in SPOT that
		  translate LTL formul\ae{} to transition based generalized
		  B\"uchi automata (TGBA). We want to implement a third
		  translation for comparison. This new method translates the
		  LTL formula into an alternating automaton, and then applies
		  a nondeterminisation algorithm which takes as input the
		  alternating automaton and gives out a TGBA. \\ To complete
		  this task, the alternating automaton structure will first
		  be set up in SPOT, then the nondeterminization algorithm
		  will be implemented, and last, the translation of LTL
		  formul\ae{} to alternating automata will be added.},
  resume	= {SPOT est une biblioth\`eque de \emph{model checking}
		  bas\'ee sur l'approche par automates et sur les automates
		  de B\"uchi g\'en\'eralis\'es bas\'es sur les transitions
		  (TGBA) pour la v\'erification de syst\`emes exprim\'es sous
		  forme de formules logiques. L'approche automate consiste
		  \`a traduire une formule logique LTL en un automate qui
		  reconna\^it le m\^eme language. Dans l'\'etat actuel des
		  choses, il existe deux algorithmes dans SPOT de traduction
		  de formules LTL vers des TGBA. Un troisi\`eme algorithme y
		  sera rajout\'e. Ce dernier convertira dans un premier temps
		  la formule LTL en un automate alternant, puis appliquera un
		  algorithme de nond\'eterminisation sur celui-ci pour
		  obtenir un TGBA. Le but de cette nouvelle impl\'ementation
		  est de mener une comparaison avec les deux autres d\'ej\`a
		  en place. \\ Pour mener \`a bien cette t\^ache, la
		  structure des automates alternants sera int\'egr\'ee dans
		  SPOT, puis ce sera au tour de l'algorithme de
		  nond\'eterminisation d'automates alternants vers des TGBA
		  et enfin la traduction de formules LTL sous forme d'automates alternants.},
  url		= {http://publis.lrde.epita.fr/200906-Seminar-DaMota},
  urllrde	= {200906-Seminar-DaMota},
  number	= 0908
}

@TechReport{	  david.04.seminar,
  oldkeys	= {attr-tech-rep},
  title		= {Attribute grammars for {C++} disambiguation},
  author	= {Valentin David},
  institution	= {LRDE},
  year		= 2004,
  urllrde	= {20041201-Seminar-David-Attribute-Report},
  number	= 0405
}

@TechReport{	  deledalle.07.seminar,
  author	= {Charles-Alban Deledalle},
  title		= {Factor analysis based channel compensation in speaker
		  verification},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200705-Seminar-Deledalle}
		  ,
  urllrde	= {200705-Seminar-Deledalle},
  number	= 0705
}

@TechReport{	  deledalle.08.seminar,
  author	= {Charles-Alban Deledalle},
  title		= {{SVM} Kernel Combining System for Speaker Verification},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200801-Seminar-Deledalle}
		  ,
  urllrde	= {200801-Seminar-Deledalle},
  abstract	= {The best speaker verification systems are based on score
		  combination of several approaches. Support Vector Machines
		  (SVM) give very hopeful results. Thus, combining these
		  methods could be very efficient. In our approach, we
		  propose a new combination method for speaker verification
		  systems based on SVM methods. This one performs a linear
		  combination of several kernel functions in order to produce
		  a new kernel function. In this combination, the weights are
		  speaker dependent, by opposition of score combination
		  approach for which the weight are universal. The idea is to
		  adapt the combination weights for each speaker in order to
		  take the advantage of the best kernel. In our experiment,
		  combinations are performed on several kernel functions: the
		  GLDS kernel, linear and Gaussian GMM supervector kernels.
		  The method can use every kernel functions with no
		  modification. The experiments are done on the NIST-SRE 2005
		  and 2006 (all trials) database.},
  resume	= {Les meilleurs syst\`emes de Verification du Locuteur (VL)
		  sont fond\'es sur la fusion des scores de d\'ecision de
		  plusieurs approches. Les m\'ethodes bas\'ees sur les
		  S\'eparateurs \`a Vaste Marge (SVM) donnent des r\'esultats
		  tr\`es performants. En cons\'equence, l'apport de ces
		  m\'ethodes est tr\`es important pour la fusion. Dans notre
		  approche, nous proposons une nouvelle m\'ethode de fusion
		  des syst\`emes de VL bas\'es sur les m\'ethodes SVM en
		  construisant une nouvelle fonction noyau \`a partir d'une
		  combinaison lin\'eaire de plusieurs fonctions. Dans cette
		  combinaison, les poids utilis\'es varient selon les
		  locuteurs, ce qui diff\`ere des approches par fusion de
		  score qui elles utilisent des poids universels. L'id\'ee
		  est donc de tirer avantage des performances de chacun des
		  noyaux, et cela pour chaque locuteur donn\'e. Ces
		  combinaisons sont effectu\'ees sur plusieurs types de
		  noyaux dont les noyaux GLDS, GMM supervecteurs lin\'eaires
		  et Gaussiens. Les exp\'eriences sont r\'ealis\'ees sur la
		  base des corpus NIST-SRE 2005 et 2006.},
  number	= 0757
}

@TechReport{	  delmon.07.seminar,
  oldkeys	= {delmon.07.seminar.eps.removal},
  author	= {Vivien Delmon},
  title		= {Generic epsilon-removal},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200706-Seminar-Delmon},
  urllrde	= {200706-Seminar-Delmon},
  number	= 0743
}

@TechReport{	  delmon.08.seminar,
  author	= {Vivien Delmon},
  title		= {Rational Expression Parser},
  titre		= {Parser d'expressions rationnelles},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200806-Seminar-Delmon},
  urllrde	= {200806-Seminar-Delmon},
  abstract	= {The Vaucanson library is designed to manipulate automata
		  and transducers. Therefore we need a rational expression
		  parser which deals with transducers. The current rational
		  expression parser only takes as input weighted rational
		  expression. The new parser allows us to specify any kind of
		  weight and any kind of monoid like free monoid product.
		  Both of these features are mandatory if we want to deal
		  with transducers. The new parser is also less restrictive
		  and provides more freedom to the user who can easily change
		  the form of the grammar used to write its expression.},
  resume	= {La biblioth\`eque Vaucanson permet de manipuler des
		  automates et des transducteurs. Le parser d'expression
		  rationnelles doit donc lui aussi traiter ces diff\'erentes
		  structures. Malheureusement l'ancien parser ne permettait
		  pas de lire des expressions rationnelles d\'ecrivant des
		  transducteurs ou m\^eme des automates \`a poids autres que
		  des nombres. Le nouveau parser permet de lire des
		  expressions rationnelles contenant des poids de toutes
		  sortes et des alphabets d\'efinis sur des produits de
		  mono\"ides. Ces diff\'erentes am\'eliorations permettent
		  d'interpr\'eter des expressions rationnelles complexes
		  repr\'esentant entre autres des transducteurs. },
  number	= 0810
}

@TechReport{	  delmon.08.seminar.reduce,
  author	= {Vivien Delmon},
  title		= {Automata Reduction},
  titre		= {Reduction d'automates},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200901-Seminar-Delmon},
  urllrde	= {200901-Seminar-Delmon},
  abstract	= { A deterministic automaton can be minimized efficiently
		  into an automaton that has a minimal number of states. The
		  reduction algorithm presented here produces an automaton
		  with a minimal number of states from a non deterministic
		  automaton with weights defined in a field. This algorithm
		  computes the base of the vector space generated by the
		  series represented by the automaton and produces an
		  automaton with a number of states equal to the dimension of
		  this base. To find this base the algorithm has to solve a
		  system of linear equations, this step requires the semiring
		  to be a field. We also want to run our algorithm on fields
		  that are not commutative which forbids the use of classical
		  solvers for these systems. This report shows how we deal
		  with these different constraints. We also present a
		  modified algorithm to work with series over Z semiring
		  which is not a field but has some sufficient properties. },
  resume	= {Un automate d\`eterministe peut \^etre minimis\`e de
		  mani\`ere efficace et donne un automate dont le nombre
		  d'\'etats est minimal. L'algorithme de r\'eduction
		  pr\'esent\'e dans ce rapport permet de construire un
		  automate dont le nombre d'\'etats est minimal \`a partir
		  d'un automate non d\'eterministe dont les poids sont
		  d\'efinis sur un semi-anneau qui est un corps. L'algorithme
		  calcule pour cela la base de l'espace vectoriel engendr\'e
		  par la s\'erie repr\'esent\'e par l'automate, ce qui permet
		  de construire un automate dont le nombre d'\'etats est
		  \'egal \`a la dimension de cette base. L'algorithme se base
		  sur la repr\'esentation matricielle des automates et nous
		  am\`ene \`a r\'esoudre un syst\`eme d'\'equations
		  lin\'eaires, ce qui force le semi-anneau de notre s\'erie
		  \`a avoir les propri\'et\'es d'un corps. Nous voulons aussi
		  que notre algorithme fonctionne sur des s\'eries dont le
		  semi-anneau est un corps non commutatif ce qui nous
		  emp\^eche d'utiliser les techniques classiques de
		  r\'esolution de syst\`emes lin\'eaires. Ce rapport montre
		  comment passer outre ces difficult\'es. Nous verrons enfin
		  comment adapter notre algorithme pour qu'il fonctionne sur
		  Z qui n'est pas un corps mais qui poss\`ede des propri\'et\'es suffisantes. },
  number	= 0830
}

@TechReport{	  denuziere.09.seminar,
  author	= { Lo\"ic Denuzi\`ere },
  title		= {{CLIMB}: A Dynamic Approach To Generic Image Processing},
  titre		= { {CLIMB}: Une approche dynamique du traitement
		  g\'en\'erique d'images },
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  url		= {http://publications.lrde.epita.fr/200905-Seminar-Denuziere}
		  ,
  urllrde	= {200801-Seminar-Denuziere},
  abstract	= { Olena is one of the most advanced image processing
		  libraries in terms of genericity. Its fully static design
		  allows for high performance, although sometimes at the cost
		  of overweighted syntax and longer compilation times. This
		  makes it less convenient for incremental development,
		  experimentation and rapid prototyping. We will present a
		  different approach to generic image processing which, while
		  using the same domain model as Olena, focuses on dynamicity
		  aspects and offers a totally different use of the library.
		  The cornerstone is the Common Lisp programming language
		  which opens a perspective for interactive use, on-the-fly
		  creation of image types and algorithms as well as a clear,
		  customizable and extensible syntax for common operations.
		  },
  resume	= { Olena est l'une des biblioth\`eques de traitement
		  d'images dont la g\'en\'ericit\'e est la plus pouss\'ee.
		  Son mod\`ele enti\`erement statique permet de tr\`es bonnes
		  performances, au prix d'une syntaxe alourdie et de temps de
		  compilation importants. Ces aspects la rendent moins
		  efficace pour le d\'eveloppement incr\'emen\-tal,
		  l'exp\'erimentation et le prototypage rapide. Nous
		  pr\'esenterons une approche diff\'erente du traitement
		  d'images g\'en\'erique qui utilise la m\^eme mod\'elisation
		  du domaine qu'Olena mais se concentre sur les aspects
		  dynamiques, offrant ainsi une utilisation totalement
		  diff\'erente de la biblioth\`eque. La pierre angulaire est
		  le langage Common Lisp qui permet une utilisation
		  interactive, la cr\'eation \`a la vol\'ee de nouveaux types
		  d'images ou de nouveaux algorithmes, tout en offrant une
		  syntaxe claire, personnalisable et extensible pour les op\'erations courantes. },
  number	= 0906
}

@TechReport{	  denuziere.10.seminar,
  author	= {Lo\"ic Denuzi\`ere},
  title		= {Property-Based Genericity: A Dynamic Approach},
  titre		= {La g\'en\'ericit\'e par propri\'et\'es},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  url		= {http://publications.lrde.epita.fr/201006-Seminar-Denuziere}
		  ,
  urllrde	= {201006-Seminar-Denuziere},
  abstract	= { Property-based genericity is an object-oriented
		  programming paradigm. It allows to model in a generic way
		  some systems which are hard to represent using classical
		  object-oriented programming. It was introduced by the
		  C++-oriented SCOOP paradigm used in Olena, an image
		  processing library. The key principle of this paradigm is
		  the description of classes in terms of a list of the
		  properties its instances must have, instead of their
		  inheritance trees.\par We will present this paradigm and
		  show that it can be extended to other languages than C++
		  and other fields than image processing. We will then
		  introduce an example implementation of property-based
		  genericity in Common Lisp, which will take advantage of its
		  dynamic capabilities and its extensibility. },
  resume	= { La g\'en\'ericit\'e par propri\'et\'es est un paradigme
		  qui \'etend la programmation orient\'ee objet et l'adapte
		  \`a certains syst\`emes pathologiques. Elle a \'et\'e
		  introduite au LRDE par le paradigme orient\'e C++ SCOOP. Le
		  principe est de caract\'eriser une classe par les
		  propri\'et\'es de ses instances au lieu de ses relations
		  d'h\'eritage. Nous pr\'esenterons ce paradigme et
		  montrerons qu'il peut \^etre utilis\'e ind\'ependamment du
		  langage et du domaine d'application. Nous introduirons
		  ensuite un exemple d'impl\'ementation en Common Lisp. },
  oldresume	= { La g\'en\'ericit\'e par propri\'et\'es est un paradigme
		  de programmation orient\'ee objet qui permet de mod\'eliser
		  de mani\`ere g\'en\'erique certains syst\`emes d\'elicats
		  \`a repr\'esenter en programmation objet classique. Elle a
		  \'et\'e introduite par le paradigme orient\'e C++ SCOOP
		  utilis\'e dans Olena, une biblioth\`eque de traitement
		  d'images. Le principe fondamental est de caract\'eriser une
		  classe non pas par ses relations d'h\'eritage, mais par une
		  liste des propri\'et\'es que poss\`edent ses instances.\par
		  Nous pr\'esenterons ce paradigme et montrerons qu'il peut
		  s'\'etendre \`a d'autres langages que le C++ et d'autres
		  domaines d'application que le traitement d'images. Nous
		  introduirons ensuite un exemple d'impl\'ementation de
		  g\'en\'ericit\'e par propri\'et\'es en Common Lisp qui tire
		  parti des capacit\'es dynamiques de ce langage ainsi que de son extensibilit\'e. },
  number	= 1003
}

@TechReport{	  denuziere.11.seminar,
  author	= {Lo\"ic Denuzi\`ere},
  title		= {Designing the user interface for a Common Lisp generic
		  library},
  titre		= {Concevoir l'interface d'une biblioth\`eque g\'en\'erique
		  en Common Lisp},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  url		= {http://publications.lrde.epita.fr/201119-Seminar-Denuziere}
		  ,
  urllrde	= {201119-Seminar-Denuziere},
  abstract	= {Climb is a generic image processing library. It is
		  implemented in Common Lisp and aims at maximal dynamism and
		  ease of use. To achieve such a goal, the user interface
		  must be at the same time powerful enough to avoid hiding
		  some functionality of the underlying design, and intuitive
		  for the user. The difficulty is to design an interface
		  which makes as few trade-offs as possible between these
		  characteristics, while staying extensible in order to keep
		  them as the library grows. After a few reminders about the
		  generic design of Climb, we present the modifications we
		  made to its existing front-end to improve its usability
		  without restraining its capabilities.},
  resume	= {Climb est une biblioth\`eque de traitement d'images
		  g\'en\'erique. Elle est impl\'ement\'ee en Common Lisp et
		  vise un dynamisme et une facilit\'e d'utilisation maximaux.
		  Dans ce but, l'interface utilisateur doit \^etre \`a la
		  fois suffisamment puissante pour ne pas cacher certaines
		  fonctionnalit\'es de la biblioth\`eque sous-jacente, et
		  intuitive pour l'utilisateur. La difficult\'e est de
		  cr\'eer une interface faisant un minimum de compromis entre
		  ces caract\'eristiques, tout en restant suffisamment
		  extensible pour les garder quand la biblioth\`eque
		  \'evolue. Apr\`es quelques rappels sur le design
		  g\'en\'erique de Climb, nous pr\'esentons les modifications
		  que nous avons apport\'ees \`a l'interface existante pour
		  am\'eliorer son utilisabilit\'e sans restreindre ses capacit\'es. }
}

@TechReport{	  depres.05.seminar,
  oldkeys	= {depres.reg-bench.05.seminar},
  author	= { Nicolas Despres },
  title		= { Regression benchmarking },
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2005,
  urllrde	= {200506-Seminar-Despres},
  number	= 0513
}

@TechReport{	  despres.04.seminar,
  oldkeys	= {depres.reg-bench.05.seminar},
  author	= { Nicolas Despres },
  title		= { C++ Transformations panorama },
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2004,
  urllrde	= {200406-Seminar-Despres},
  number	= 0410
}

@TechReport{	  duhamel.08.seminar,
  author	= {Guillaume Duhamel},
  title		= {Stage de traitement d'image au {LRDE}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200801-Seminar-Duhamel},
  urllrde	= {200801-Seminar-Duhamel},
  number	= 0804
}

@TechReport{	  durlin.07.seminar,
  oldkeys	= {durlin.07.seminar.disambiguation},
  author	= {Renaud Durlin},
  title		= {Semantics driven disambiguation},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200706-Seminar-Durlin},
  urllrde	= {200706-Seminar-Durlin},
  abstract	= {An elegant approach to manage ambiguous grammars consists
		  in using a generalized LR parser which will not produce a
		  parse tree but a parse forest. An additional step, called
		  disambiguation, occurring just after the parsing, is then
		  necessary. The disambiguation process consists in analyzing
		  the parse forest to choose the only good parse tree using
		  semantics rules. We use this approach in Transformers with
		  the attribute grammars formalism. The lab work will be a
		  comparison between this formalism and two other methods of
		  disambiguation: the first one using ASF+SDF and the second
		  one using Stratego language. The goal of this comparison
		  will try to emphasize that attribute grammars are perfect
		  to solve the disambiguation problem. Another thing will be
		  to find the weakness of this method compared to the two
		  others for a possible improvement of the system used in
		  Transformers.},
  resume	= {Une approche \'el\'egante pour g\'erer les grammaires
		  ambigu\"es consiste \`a utiliser un parseur LR
		  g\'en\'eralis\'e qui produira non pas un arbre mais une
		  for\^et de parse. Une \'etape suppl\'ementaire, appel\'ee
		  d\'esambiguisation, survenant juste apr\`es le parsing, est
		  alors n\'ecessaire. Celle-ci consiste analyser cette
		  for\^et pour obtenir l'unique arbre valide correspondant
		  \`a l'entr\'ee en prenant en compte les r\`egles de
		  s\'emantiques contextuelles. C'est cette approche qui a
		  \'et retenue dans Transformers avec le formalisme des
		  grammaires attribu\'ees. Le travail effectu\'e pr\'esentera
		  une comparaison entre ce formalisme et deux autres
		  techniques de d\'esambiguisation : la premi\`ere \`a l'aide
		  d'ASF+SDF et la deuxi\`eme \`a l'aide du langage Stratego.
		  Le but de cette comparaison sera double : montrer que les
		  grammaires attribu\'ees sont parfaitement adapt\'ees \`a ce
		  probl\`eme et exhiber les faiblesses de celles-ci par
		  rapport aux deux autres m\'ethodes en vue d'une
		  am\'elioration possible du syst\`eme utilis\'e dans Transformers.},
  number	= 0709
}

@TechReport{	  durlin.08.seminar,
  author	= {Renaud Durlin},
  title		= {Semantics driven disambiguation: A comparison of different
		  approaches},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200801-Seminar-Durlin},
  urllrde	= {200801-Seminar-Durlin},
  abstract	= {Modularity, scalability and expressiveness, three main
		  aspects for a disambiguation system. Disambiguation is the
		  step occurring just after the parsing that consists in
		  analyzing the output given by a generalized LR parser. The
		  goal is to choose, amongst the many parse trees, the right
		  one that corresponds to the input using semantics rules. By
		  means of a comparison with two other methods based on SDF
		  (the first one using ASF formalism and the second one using
		  Stratego language), our approach, attribute grammars, will
		  be evaluated with respect to these three aspects to bring
		  out its strengths and its weaknesses.},
  resume	= {Modularit\'e, extensibilit\'e et expressivit\'e, trois
		  aspects fondamentaux pour un syst\`eme de
		  d\'esambigu\"isation. La d\'esambigu\"isation est l'\'etape
		  survenant juste apr\`es l'analyse syntaxique qui consiste
		  \`a analyser la sortie obtenue lors de l'utilisation d'un
		  parseur LR g\'en\'eralis\'e. Le but de cette \'etape
		  \'etant de s\'electionner, parmi toute une for\^et,
		  l'unique arbre valide correspondant \`a l'entr\'ee en
		  prenant en compte les r\`egles de s\'emantique
		  contextuelles. Au travers d'une comparaison avec deux
		  autres techniques reposant sur SDF (le formalisme ASF et le
		  langage Stratego), le syst\`eme de grammaires attribu\'ees
		  utilis\'e dans Transformers sera \'evalu par rapport \`a
		  ces aspect fondamentaux pour en faire ressortir les avantages et inconv\'enients.},
  number	= 0802
}

@TechReport{	  fiette.11.seminar,
  author	= {Guillaume Fiette},
  title		= {Progresses towards Vaucanson 1.4 and 2.0},
  titre		= {Avanc\'ees vers Vaucanson 1.4 et 2.0},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  abstract	= {VAUCANSON is a finite state machine manipulation platform
		  for automata and transducers. Usage highlighted the overly
		  complex interface for the automaton manipulation.
		  Therefore, work was done during the past years to improve
		  it, leading to the introduction of the concept of automaton
		  "kinds". Two different versions of the platform are
		  currently under development. VAUCANSON 1.4, which will be a
		  more complete and stable version of the work done before
		  the interface modification. Idea is to work toward
		  releasing a final version of VAUCANSON 1.X, allowing us to
		  focus on VAUCANSON 2.0, which is currently incomplete, due
		  to the deep changes that "kinds" brought to the library.
		  This report will explain a new feature of VAUCANSON 1.4,
		  the Z/nZ semirings, and presents what has been and will be
		  done to get VAUCANSON 2.0 to work.},
  resume	= {VAUCANSON est une plateforme de manipulation d'automates
		  finis et de transducteurs. Apr\`es plusieurs ann\'ees de
		  developpement, il f\^ut constat\'e que l'interface mise en
		  place pour manipuler les automates \'etait trop complexe.
		  Des travaux furent donc entrepris pour r\'esoudre ce
		  probl\`eme, amenant ainsi \`a l'introduction des "label
		  kinds".\\ Deux versions de la plateforme sont donc en
		  developpement aujourd'hui: VAUCANSON 1.4, qui vise a
		  terminer et compl\'eter le travail effectu\'e avant
		  l'introduction des kinds et VAUCANSON 2.0, derni\`ere
		  version de la plateforme, pour le moment incompl\`ete.\\ Ce
		  rapport a pour but de pr\'esenter une nouvelle
		  fonctionnalit\'e de VAUCANSON 1.4, les semi-anneaux Z/nZ,
		  ainsi que le travail en cours sur VAUCANSON 2.0.},
  url		= {http://publications.lrde.epita.fr/201107-Seminar-Fiette},
  urllrde	= {201107-Seminar-Fiette},
  number	= 1113
}

@TechReport{	  folio.08.seminar,
  author	= {Etienne Folio},
  title		= {Distance Transform},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  urllrde	= {200807-Seminar-Folio},
  abstract	= {A distance transform, also known as distance map or
		  distance field, is a representation of a distance function
		  to an object, as an image. Such maps are used in several
		  applications, especially in document image analysis. Some
		  optimizations can be obtained by less generic methods: for
		  example, maps calculated by front propagation can determine
		  shorter paths, assuming that the image is non-convex. This
		  presentation discusses different distance transform
		  algorithms and underlines their advantages and weaknesses.
		  Finally we will explain our choices.},
  resume	= {Une carte de distances est une repr\'esentation sous forme
		  d'image d'une fonction distance \`a un objet. Ces cartes
		  sont utilis\'ees dans de nombreuses applications, en
		  particulier en analyse d'images de documents qui nous
		  serviront d'illustration. Certaines m\'ethodes de calcul de
		  cartes moins g\'en\'eriques que d'autres peuvent s'av\'erer
		  plus rapides : par exemple, des cartes calcul\'ees par
		  propagation de fronts permettent de d\'eterminer des plus
		  courts chemins mais ne fonctionnent que lorsque le support
		  est connu pour \^etre non-convexe. Cette pr\'esentation
		  fait un tour d'horizon des diff\'erents algorithmes de
		  calculs de cartes de distances, met en \'evidence leurs
		  atouts et faiblesses et explique les choix retenus.},
  number	= 0806
}

@TechReport{	  folio.09.seminar,
  author	= {Etienne Folio},
  title		= {Histograms},
  titre		= {Histogrammes},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  urllrde	= {200906-Seminar-Folio},
  abstract	= {A histogram is a representation of the distribution of
		  data in an image, e.g., gray-levels or colors. This common
		  tool is used for many applications and especially for
		  classification purposes. This key-feature has to be
		  generically implemented in the \textsc{Milena} library. In
		  this seminar, we propose to store histogram data using an
		  image container. To that aim, adapting the definition of
		  value types is required. More specifically, we propose to
		  augment the traits associated with value types, add some
		  new useful value types, and design new abstractions over
		  them. Last, we present how to deal with circular data, such
		  as the "hue" values (encoded by angles in the HSL color
		  space); in this case, the "histogram image" would become
		  also circular.},
  resume	= {Un histogramme est une repr\'esentation de la distribution
		  de donn\'ees dans une image, par exemple des niveaux de
		  gris ou des couleurs. Cette caract\'eristique essentielle
		  doit \^etre impl\'ement\'ee g\'en\'eriquement dans la
		  biblioth\`eque \textsc{Milena}. Durant ce s\'eminaire nous
		  proposons d'enregistrer les donn\'ees d'histogrammes dans
		  des conteneurs d'images. Pour cela, nous avons besoin
		  d'adapter la d\'efinition des types de valeurs. Plus
		  sp\'ecifiquement, nous proposons d'augmenter les traits
		  associ\'es aux types de valeurs, d'ajouter de nouveaux
		  types de valeurs utiles et de construire de nouvelles
		  abstractions au-dessus. Enfin nous pr\'esenterons comment
		  traiter des donn\'ees circulaires comme les valeurs de
		  teinte (encod\'ees par des angles dans l'espace de couleurs
		  HSL); dans ce cas "l'image histogramme" deviendrait aussi circulaire.},
  number	= 0907
}

@TechReport{	  fosse.04.seminar,
  oldkeys	= {fosse.dynamic-libs.04.seminar},
  author	= {Lo\"ic Fosse},
  title		= {Dynamic use of statically typed libraries, \textsc{Just In
		  Time} compilation and other solutions},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2004,
  urllrde	= {200406-Seminar-Fosse},
  number	= 0406
}

@TechReport{	  galtier.08.seminar,
  author	= {J\'er\^ome Galtier},
  title		= {Improving {Vaucanson}'s transducers composition
		  algorithm},
  titre		= {Am\'elioration de la composition des transducteurs dans
		  {Vaucanson}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  abstract	= {Vaucanson is a library aimed at providing easy access and
		  manipulation of common automata constructions and their
		  algorithms. As such it provides schoolbook algorithms (and
		  some others on the bleeding edge) such as determinization,
		  accessible states calculation and so on. One of them is
		  composition of transducers. This algorithm isn't from an
		  obvious kind and his implementation in Vaucanson is
		  perfectible. Improving such an algorithm implementation is
		  consequently a good way to challenge Vaucanson design
		  choices.},
  resume	= {Vaucanson est une biblioth\`eque dont un des buts est de
		  permettre un acc\`es facilit\'e \`a des automates et aux
		  algorithmes qui leur sont associ\'es. Elle met donc \`a
		  notre disposition plusieurs algorithmes standard (et
		  d'autres moins conventionnels) tels que la
		  d\'eterminisation, le calcul des \'etats accessibles etc.
		  L'un de ces algorithmes est la composition de
		  transducteurs. Celui-ci n'est pas d'une nature ais\'ee \`a
		  aborder et son impl\'ementation dans Vaucanson est
		  perfectible. Am\'eliorer l'impl\'ementation d'un tel
		  algorithme est alors un bon moyen de mettre \`a l'\'epreuve
		  certains choix de conception dans Vaucanson.},
  url		= {http://publis.lrde.epita.fr/200807-Seminar-Galtier},
  urllrde	= {200807-Seminar-Galtier},
  number	= 0824
}

@TechReport{	  galtier.09.seminar,
  author	= {J\'er\^ome Galtier},
  title		= {Remedial treatment for {Vaucanson}: an enhanced automaton
		  concept},
  titre		= {Traitement curatif pour {Vaucanson}: un renforcement du
		  concept d'automate},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  abstract	= { Vaucanson allows you to manipulate finite state machines.
		  So the modeling of these objects plays a central role
		  concerning the genericity of the library. We want to be
		  able to extend the model to support new types and to
		  specialize behaviours in order to improve performances.\\
		  We will expose what can be considered as a Gordian knot in
		  the actual modeling: for example Vaucanson is unable to
		  choose the implementation of an automaton according to one
		  of its properties. The proposed solution will reinstate a
		  sane modeling and will prevent misconceptions while
		  devising algorithm specifications. Finally, we will
		  describe among other things a collection of specializations
		  of the automaton concept and a set of improvements to the
		  model that were previously too expensive to implement.},
  resume	= { Vaucanson permet de manipuler des automates finis. La
		  mod\'elisation de ces objets occupe donc une place centrale
		  dans la g\'en\'ericit\'e de la biblioth\`eque. Nous voulons
		  pouvoir \'etendre cette mod\'elisation pour supporter de
		  nouveaux types et sp\'ecialiser des comportements afin
		  d'am\'eliorer les performances.\\ Nous exposerons ce qui
		  peut \^etre consid\'er\'e comme un v\'eritable n\oe{}ud
		  gordien dans la mod\'elisation actuelle: Vaucanson est par
		  exemple incapable de choisir une impl\'ementation pour un
		  automate en fonction d'une de ses propri\'et\'es. La
		  solution apport\'ee restaure alors une mod\'elisation saine
		  et emp\^echera des erreurs de conception lors de la
		  recherche de sp\'ecifications des algorithmes. Finalement,
		  nous exposerons, entre autre, une s\'erie de
		  sp\'ecialisations du concept d'automate, ainsi qu'un
		  ensemble d'am\'eliorations du mod\`ele qui \'etaient
		  autrefois trop co\^uteuses \`a mettre en place.},
  url		= {http://publis.lrde.epita.fr/200905-Seminar-Galtier},
  urllrde	= {200905-Seminar-Galtier},
  number	= 0909
}

@TechReport{	  galtier.10.seminar,
  author	= {J\'er\^ome Galtier},
  title		= {Adapting the data structures of {Vaucanson} to the concept
		  of kind and a new interface},
  titre		= {Adapter les structures de donn\'ees de {Vaucanson} au
		  concept de kind et \`a une interface r\'enov\'ee},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  abstract	= { The design of automata in Vaucanson plays a central role
		  concerning the genericity of the library. We want to be
		  able to extend the model to support new types and to
		  specialize behaviours in order to improve performances. The
		  recent introduction of the kind concept in the library
		  together with the definition of a new automata interface,
		  are targeting the rationalisation of already existing data
		  structures in Vaucanson --- Boost Multi Index based graphs
		  for example.\\ The kind of an automaton is the type of the
		  labels on the transitions like a letter or a word. Through
		  an iterator hierarchy respecting the new interface, the
		  user can efficiently iterate over the transitions labeled
		  by a specific occurrence of the kind specified by a
		  predicate --- iterating over all the transitions labeled by
		  an $a$ for example. The gain is noticeable because the user
		  had no choices but to iterate over a polynomial before
		  those improvements. },
  resume	= { La conception des automates dans Vaucanson occupe une
		  place centrale concernant la g\'en\'ericit\'e de la
		  biblioth\`eque. Nous voulons pouvoir \'etendre cette
		  mod\'elisation pour supporter de nouveaux types et
		  sp\'ecialiser des comportements afin d'am\'eliorer les
		  performances. L'introduction r\'ecente du concept de kind
		  \`a la biblioth\`eque ainsi que la d\'efinition d'une
		  nouvelle interface des automates ont pour objectifs de
		  rationaliser les structures de donn\'ees d\'ej\`a
		  pr\'esentes dans Vaucanson, comme les graphes utilisant
		  Boost Multi Index.\\ Le kind d'un automate est le type
		  d'\'etiquettes qu'il porte sur ses transitions, une lettre
		  ou un mot par exemple. L'utilisateur peut alors, \`a
		  travers une hi\'erarchie d'it\'erateurs respectant la
		  nouvelle interface, it\'erer de mani\`ere efficace sur les
		  transitions portant une occurrence de ce kind sp\'ecifi\'e
		  comme pr\'edicat (it\'erer sur les transitions portant la
		  lettre $a$ par exemple). Le gain est visible car
		  l'utilisateur \'etait contraint d'it\'erer sur le support
		  d'un polyn\^ome avant ces am\'eliorations. },
  url		= {http://publications.lrde.epita.fr/201001-Seminar-Galtier},
  urllrde	= {201001-Seminar-Galtier},
  number	= 0916
}

@TechReport{	  garcia-ballester.08.seminar,
  author	= {Jean-Philippe Garcia Ballester},
  title		= {Fictious Play},
  titre		= {\'Etude du fictitious play dans le cas d'un jeu \`a
		  fonctions d'utilit\'e identiques},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  urllrde	= {200801-Seminar-Garcia},
  abstract	= {Le fictitious play, en th\'eorie des jeux, est une r\`egle
		  d'apprentissage dans laquelle chaque joueur suppose que ses
		  adversaires jouent une strat\'egie fixe (potentiellement
		  mixte, c'est-\`a-dire une distribution de probabilit\'e sur
		  un ensemble de strat\'egies). \`A chaque tour, chaque
		  joueur joue ainsi le meilleur coup contre la strat\'egie de
		  ses adversaires, d\'etermin\'ee de mani\`ere empirique \`a
		  partir de leurs coups pr\'ec\'edents. La convergence de
		  telles strat\'egies n'est pas assur\'ee, mais on sait que
		  si il y a convergence, alors les strat\'egies jou\'ees
		  correspondront statistiquement \`a un \'equilibre de Nash.
		  Il est donc tr\`es int\'eressant de conna\^itre les
		  crit\`eres de convergence. Nous nous int\'eresserons pour
		  cette pr\'esentation au cas des jeux o\`u les fonctions
		  d'utilit\'e (le gain d'un joueur en fonction des
		  strat\'egies jou\'ees) de chaque joueur sont identiques.
		  Nous \'etudierons d'abord des r\'esultats de convergence
		  dans ce cas particulier. Afin de r\'eduire la complexit\'e
		  en temps, nous verrons une variante de cet algorithme, qui
		  consiste \`a autoriser une erreur dans la meilleure
		  r\'eponse des joueurs. Nous pr\'esenterons enfin un exemple
		  d'application du fictitious play pour r\'esoudre un
		  probl\`eme a priori non li\'e \`a la th\'eorie des jeux :
		  un probl\`eme d'optimisation, c'est-\`a-dire calculer le maximum des valeurs prises par une fonction.},
  resume	= {Fictitious play, in game theory, is a learning rule in
		  which each player presumes that his opponents are playing a
		  stationary strategy ---potentially mixed, i.e. a
		  probability distribution over a set of strategies. At each
		  round, each player thus best responds to his opponents'
		  strategy, computed empirically using their previous moves.
		  Convergence of such strategies is not always assured, yet
		  we know that if there is convergence, then the strategies
		  used will correspond statistically to a Nash-equilibrium.
		  It is thus very interesting to know when fictitious play
		  converges. We will address for this presentation the case
		  where utility functions ---a player's payoff with respect
		  to the played strategies--- of each player are identical.
		  We will first study results about convergence in this
		  special case. In order to reduce the computationnal
		  complexity we will see a modified version of this algorithm
		  that allows errors in players' best replies. We will
		  finally introduce an example of use of fictitious play to
		  solve a problem not a priori connected to game theory: an
		  optimization problem, i.e. computing the maximum of the
		  values taken by a function.}
}

@TechReport{	  garrigues.08.seminar,
  author	= {Matthieu Garrigues},
  title		= {Stage de traitement d'image au {LRDE}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200801-Seminar-Garrigues}
		  ,
  urllrde	= {200801-Seminar-Garrigues},
  number	= 0803
}

@TechReport{	  garrigues.08.seminar.fllt,
  author	= {Matthieu Garrigues},
  title		= {Fast Level Line Transform},
  titre		= {Transformation des courbes de niveau rapide},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  abstract	= {The {Fast Level Line Transform} ({FLLT}) constructs a
		  contrast-invariant representation of an image. This
		  algorithm builds a tree which follows the inclusion of the
		  shapes contained in an image. For an image filter, having
		  the contrast-invariant property is interesting. For
		  instance, in the field of document image analysis, this
		  representation is precious to extract characters whatever
		  their mean gray-levels are brighter or darker than their
		  surroundings. This document presents how this algorithm is
		  introduced in our image processing library and shows the
		  results of some connected that can be derived from this
		  representation.},
  resume	= {La transformation rapide des courbes de niveaux ({FLLT})
		  construit une repr\'esentation d'une image ind\'ependante
		  du contraste. Cet algorithme construit un arbre suivant les
		  inclusions des formes. Pour un filtre, \^etre invariant
		  suivant le contraste est un plus. Par exemple, en analyse
		  de document, cette repr\'esentation a le pr\'ecieux
		  avantage d'extraire facilement et rapidement les
		  caract\`eres ind\'ependamment du fait qu'ils soient plus
		  clairs ou plus fonc\'es que leur voisinage. Ce document
		  pr\'esente l'introduction de l'algorithme dans notre
		  biblioth\`eque de traitement d'images et montre les
		  r\'esultats de quelques filtres connect\'es que peut
		  engendrer cette repr\'esentation.},
  url		= {http://publis.lrde.epita.fr/200806-Seminar-garrigues},
  urllrde	= {200806-Seminar-garrigues},
  number	= 0814
}

@TechReport{	  garrigues.09.seminar,
  author	= {Matthieu Garrigues},
  title		= {Tarjan Union-Find algorithm and connected operators},
  titre		= {L'algorithme Union-Find de Tarjan et les filtres
		  connect\`es},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  abstract	= {Tarjan Union-Find algorithm (TUFA) aims to build, given an
		  image, a tree representation modeling the equivalence
		  classes following a given relation. It can be derived to
		  define filters on those tree representations. TUFA is
		  currently used in Milena, our image processing library, to
		  implement connected filters. For example, closing and
		  opening related to area, volume, or height which are useful
		  to clean an image while preserving contours. This important
		  property provides a nice advantage in comparison to the
		  classical opening and closing based on erosion and
		  dilation. Another advantage of TUFA is that it can be used
		  for algorithms which feature the domain disjointness
		  property. This document presents how new connected filters,
		  in particular self-dual, have been introduced into
		  Milena.},
  resume	= {L'algorithme Union-Find de Tarjan (TUFA) produit, \`a
		  partir d'une image, un arbre repr\`esentant des classes
		  d'\`equivalences dans une image \`etant donn\`ee une
		  relation. Cette repr\`esentation peut \^etre utilis\`ee
		  pour d\`efinir des filtres. Cette m\`ethode est
		  actuellement utilis\`ee dans Milena, notre biblioth\`eque
		  de traitement d'image, pour impl\`ementer des filtres
		  connect\`es comme par exemple l'ouverture et la fermeture
		  d'aire, de volume ou encore de hauteur. Ces filtres sont
		  utilis\`es pour filtrer une image tout en pr\`eservant les
		  contours. Cette propri\`et\`e est un avantage par rapport
		  \`a l'ouverture et la fermeture bas\`ees sur l'\`erosion et
		  la dilatation. TUFA peut \^etre utilis\`e par des
		  algorithmes conservant les domaines disjoints, ce qui est
		  un second avantage int\`eressant. Ce document pr\`esente
		  une m\`ethode pour impl\`ementer une s\`erie de nouveaux
		  filtres, notamment auto duaux.},
  url		= {http://publis.lrde.epita.fr/200901-Seminar-garrigues},
  urllrde	= {200901-Seminar-garrigues},
  number	= 0832
}

@TechReport{	  gournet.04.seminar,
  author	= {Olivier Gournet},
  title		= {Progress in {C++} source preprocessing},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2004,
  number	= 0411
}

@TechReport{	  gournet.06.seminar,
  author	= {Olivier Gournet and Alexandre Borghi and Nicolas Pierron},
  title		= {Parsing with {Transformers}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2006
}

@TechReport{	  guillot.11.seminar,
  author	= {Simon Guillot},
  title		= {Writing generic image processing algorithms},
  titre		= {Ecriture d'algorithmes de traitement d'images
		  g\'en\'eriques},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  url		= {http://publications.lrde.epita.fr/URLLRDE},
  urllrde	= {URLLRDE},
  abstract	= {Climb is a generic image processing library written in
		  Lisp. The study of the implementation of a segmentation
		  algorithm by computing watersheds highlights the
		  possibilities offered by the combination of a dynamic
		  language like Lisp and a generic image representation. This
		  case study tackles basic concepts of manipulating images in
		  Climb like: sites, site-sets and accumulators.},
  resume	= {Climb est une biblioth\`eque g\'en\'erique de traitement
		  d'images en Lisp. L'\'etude de l'impl\'ementation d'un
		  algorithme de segmentation par ligne de partage des eaux
		  permet de faire \'etat des possibilit\'es offertes par un
		  langage dynamique tel que Lisp alli\'e \'a une
		  mod\'elisation g\'en\'erique des images. Cette \'etude de
		  cas permet d'aborder les concepts de base de la
		  manipulation d'images au sein de Climb tels que les sites,
		  les ensembles de sites et les accumulateurs. L'utilisation
		  de l'ensemble de ces notions reposent sur l'aspect
		  dynamique et fonctionnel de Lisp.}
}

@TechReport{	  hamelin.09.seminar,
  author	= {Alex Hamelin},
  title		= {Property based class hierarchy of {Vaucanson}'s Algebra
		  module},
  titre		= {Hi\'erarchie par propri\'et\'es du module Algebra de
		  {Vaucanson}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  abstract	= {In Vaucanson, Finite State Machines are mathematically
		  defined by an algebraic structure module called Algebra.
		  Considering the algebraic mathematical definitions,
		  however, the current design is inaccurate: some
		  hierarchical relations are false (for example, the
		  inheritance between semirings and monoids). Moreover, we
		  are unable to add new algebraic structures easily.\newline
		  Therefore, in order to give Algebra more granularity in its
		  algebraic concept definitions, it is necessary to rework
		  its current structure by introducing a property based class
		  hierarchy similar to the one presented in SCOOP. Using the
		  mathematical operator and set properties to define
		  algebraic structures, as opposed to a usual class
		  hierarchy, we would be able to specialize algorithms more
		  precisely thanks to structure property verifications, thus
		  increasing Vaucanson's performance and expressiveness.},
  resume	= {Le module de structures alg\'ebriques de Vaucanson,
		  Algebra, sert de base \`a la d\'efinition math\'ematique
		  des automates finis. Cependant la mod\'elisation actuelle
		  est inexacte du point de vue th\'eorique: les relations
		  d'h\'eritages entre certaines classes sont fausses
		  (l'h\'eritage entre les semi-anneaux et les mono\"\i{}des
		  en est le parfait exemple). D'autre part, nous ne pouvons
		  facilement l'\'etendre avec de nouvelles structures
		  alg\'ebriques.\newline Ainsi, afin de doter Algebra d'une
		  plus grande granularit\'e dans sa d\'efinition des concepts
		  alg\'ebriques, il est n\'ecessaire de retravailler sa
		  structure globale en introduisant un syst\`eme de
		  hi\'erarchie par propri\'et\'es similaire \`a celui
		  pr\'esent\'e dans SCOOP. En se basant sur les
		  propri\'et\'es des op\'erateurs et des ensembles
		  math\'ematiques pour d\'efinir la nature des structures
		  alg\'ebriques, et non sur une hi\'erarchie de classes
		  classique, nous pourrons nous permettre une
		  sp\'ecialisation plus pr\'ecise des algorithmes gr\^ace \`a
		  la garantie de propri\'et\'es sur ces structures,
		  entra\^inant ainsi un gain de performance et d'expressivit\'e important au c\oe{}ur de Vaucanson.},
  url		= {http://publis.lrde.epita.fr/200906-Seminar-Hamelin},
  urllrde	= {200906-Seminar-Hamelin},
  number	= 0905
}

@TechReport{	  hamelin.10.seminar,
  author	= {Alex Hamelin},
  title		= {Towards Vaucanson 2.0},
  titre		= {Vers Vaucanson 2.0},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  abstract	= {Vaucanson is a finite state machine manipulation platform
		  for automata and transducers. Usage highlighted the overly
		  complex interface for the automaton manipulation.
		  Therefore, a new approach to its definition was considered
		  involving the concept of automaton kinds. The former
		  Vaucanson development team initiated this series of
		  fundamental changes which concluded in the implementation
		  of the labels-are-letters kind. Still, these changes put
		  the library in a transitional state. \newline In the
		  continuation of their work and in order to restore both the
		  robustness and genericity of Vaucanson, we will introduce
		  two new kinds into the library: labels-are-words and
		  labels-are-series. This work may lead to a series of
		  changes involving both algorithm rewriting and data
		  structure modifications which will allow simpler yet more
		  powerful automata manipulation.},
  resume	= {Vaucanson est une plateforme de manipulation d'automates
		  finis et de transducteurs dont l'interface s'est montr\'ee
		  trop complexe. Une nouvelle approche de sa d\'efinition fut
		  par cons\'equent consid\'er\'ee, impliquant l'utilisation
		  du concept de kind d'un automate. La pr\'ec\'edente
		  \'equipe de d\'eveloppement de Vaucanson impl\'ementa le
		  kind labels-are-letters, ce qui laissa la biblioth\'eque
		  dans un \'etat transitoire. Afin de restaurer la force et
		  la g\'en\'ericit\'e de Vaucanson, le nouveau kind
		  labels-are-words sera introduit. Ce travail m\'enera \`a
		  plusieurs changements, de la r\'e\'ecriture d'algorithmes
		  \`a la modification du design de la biblioth\'eque.},
  url		= {http://publis.lrde.epita.fr/201006-Seminar-Hamelin},
  urllrde	= {201006-Seminar-Hamelin},
  number	= 1002
}

@TechReport{	  hamelin.11.seminar,
  author	= {Alex Hamelin},
  title		= {Vaucanson 2.0 Internals},
  titre		= {M\'ecanique de Vaucanson 2.0},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  abstract	= {Vaucanson is a finite state machine manipulation platform
		  for automata and transducers. Usage highlighted the overly
		  complex interface for the automaton manipulation. For the
		  past two years, active development has been undertaken to
		  introduce the concept of automaton kinds. \newline The
		  library interface was remade, and so were its internal
		  mechanics. This led to a series of changes in data
		  structures, algorithms and interface definition. We will
		  expose these modifications while trying to highlight the
		  various pitfalls one may encounter when working directly in
		  the library core. This work may lead to a performance
		  analysis between Vaucanson 2.0 and the last stable release
		  of the library.},
  resume	= {Vaucanson est une plateforme de manipulation d'automates
		  finis et de transducteurs dont l'interface s'est montr\'ee
		  trop complexe. Pendant les deux derni\`eres ann\'ees, des
		  travaux ont \'et\'e entrepris afin d'introduire le concept
		  de kind d'un automate dans la biblioth\`eque.\newline Afin
		  d'y arriver, l'interface fut refaite ainsi que la
		  m\'ecanique interne de Vaucanson. Ceci amena plusieurs
		  changements dans les structures de donn\'ees, les
		  algorithmes et la d\'efinition de l'interface. Nous
		  exposerons ces modifications tout en mettant en avant les
		  divers pi\`eges qu'un d\'eveloppeur pourrait rencontrer en
		  travaillant dans le coeur de la biblioth\`eque. Ce travail
		  pourra amener \`a des mesures de performances entre
		  Vaucanson 2.0 et la derni\`ere version stable de la biblioth\`eque.},
  url		= {http://publis.lrde.epita.fr/201117-Seminar-Hamelin},
  urllrde	= {201117-Seminar-Hamelin},
  number	= 1002
}

@TechReport{	  hocquet.06.seminar,
  author	= {Quentin Hocquet},
  title		= {{Scool} transformation towards {C++}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  urllrde	= {200607-Hocquet-Moulard},
  year		= 2006,
  number	= 0619
}

@TechReport{	  hocquet.08.seminar,
  author	= {Beno\^it Sigoure and Quentin Hocquet},
  title		= {{revCPP} A reversible {C++} preprocessor},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200801-Seminar-Hocquet},
  urllrde	= {200801-Seminar-Hocquet},
  abstract	= {Abstract: The Transformers project aims at creating a
		  generic framework for C++ source to source transformation.
		  Source to source transformation consists in refactoring the
		  code and producing a modified source. The resulting code
		  may be reread, reused, re-modified \ldots by programmers
		  and thus must be human-readable. Moreover it should respect
		  the original coding style. This process of preserving the
		  original layout is called high fidelity program
		  transformation. Transformers targets the C/C++ language.
		  Unlike many other languages, C++ source code is
		  preprocessed to obtain the actual source code. In our
		  program transformation context we need to un-preprocess the
		  code to give back a human-readable code to the programmer.
		  This document presents the work and research carried out to
		  implement a reversible C++ preprocessor and a
		  postprocessor, i.e. a tool to obtain the original code from
		  the preprocessed one. },
  resume	= {Le but du projet Transformers est de cr\'eer un framework
		  g\'en\'erique pour de la transformation source \`a source
		  de code C++. Une transformation "source \`a source"
		  consiste \`a retravailler le code et produire un fichier de
		  code source modifi\'e. Ce code peut \^etre relu,
		  r\'e-utilis\'e, modifi\'e ... par des programmeurs et doit
		  donc \^etre lisible. De plus, il doit respecter le coding
		  style d'origine. Ce processus de pr\'eservation de la mise
		  en page est appel\'e "High fidelity program
		  transformation". Transformers cible les langages C et C++.
		  Contrairement \`a de nombreux langages, le C++ est un
		  langage pr\'eprocess\'e pour obtenir le code source
		  effectif. Dans le contexte de la transformation de
		  programmes, il faut d\'e-pr\'eprocesser le code pour le
		  rendre lisible au programmeur. Ce document pr\'esente le
		  travail de recherche que nous avons men\'e pour
		  impl\'ementer un pr\'eprocesseur de C++ r\'eversible et un
		  postprocesseur, c'est-\`a-dire un outil permettant
		  d'obtenir le code d'origine \`a partir du code pr\'eprocess\'e.},
  number	= 0742
}

@TechReport{	  jardonnet.07.seminar,
  oldkeys	= {jardonnet.07.seminar.olena.canvas},
  author	= {Ugo Jardonnet},
  title		= {Canvas in Morphological Algorithms},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200706-Seminar-Jardonnet}
		  ,
  urllrde	= {200706-Seminar-Jardonnet},
  abstract	= {Olena is a generic image processing library developed at
		  LRDE. It provides many morphological algorithms.
		  Mathematical morphology offers several powerful tools in
		  image processing and analysis.\\ Similarities appear when
		  writing morphological algorithms. Thereby, we can classify
		  those tools and then build canvases of algorithms. This
		  report presents what is a canvas and why canvases matter.
		  We will see different manners to implement canvases with
		  their pro and con arguments. Finally, we will explain which
		  canvas implementation we have chosen for Olena and why.},
  resume	= {Olena est une biblioth\`eque g\'en\'erique de traitement
		  d'images d\'evelopp\'ee au LRDE. Elle propose un grand
		  nombre d'algorithmes morphologiques. La morphologie
		  math\'ematique, offre des outils tr\`es puissants de
		  traitement et d'analyse d'images.\\ Des similarit\'es
		  apparaissant dans l'\'ecriture des algorithmes
		  morphologiques, il est possible de les classifier et,
		  ainsi, de proposer un certain nombre de "canevas"
		  d'algorithmes. Ce rapport d\'efinie ce que sont les canevas
		  et les avantages qu'ils apportent. Apres une br\`eve
		  introduction \`a la morphologie math\'ematique, cet
		  expos\'e presentera diff\'erents canevas d'algorithmes retenus par Olena.},
  number	= 0753
}

@TechReport{	  jardonnet.08.seminar,
  author	= {Ugo Jardonnet},
  title		= {Fast Image Registration},
  titre		= {Recalage d'images rapide},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200806-Seminar-jardonnet}
		  ,
  urllrde	= {200806-Seminar-jardonnet},
  abstract	= {Image registration is a process widely used in image
		  processing. Considering two measurements $A$ and $B$ of the
		  same object (say, a radiography and an magnetic resonance
		  image (MRI)), this technique estimates a transformation of
		  $A$ so that the object in $A$ becomes aligned with the
		  object in $B$. Basically this technique is able to
		  superimpose the image $A$ over the image $B$, allowing the
		  client to see mixed information. This presentation will
		  discuss the implementation of a fast image registration
		  algorithm in Milena, the \Cxx generic image processing
		  library from the Olena platform, developed at LRDE.
		  Specific techniques used to improve this process will be
		  introduced.},
  resume	= {Le recalage d'images est une technique classique en
		  traitement d'image. Soit $A$ et $B$ deux images
		  repr\'esentant le m\^eme objet (par exemple une
		  radiographie et une image \`a r\'esonance magn\'etique
		  (IRM)), on calcule une transformation de $A$ telle que le
		  recalage de l'objet dans $A$ soit align\'e sur l'objet dans
		  $B$. Typiquement, cette technique peut permettre la lecture
		  simultan\'ee de deux mesures $A$ et $B$. Cet expos\'e
		  discutera des proc\'ed\'es de recalage rapide utilis\'es
		  dans Milena, la biblioth\`eque C++ g\'en\'erique de
		  traitement d'image de la plate-forme Olena, d\'evelopp\'ee
		  au LRDE. Certaines am\'eliorations seront pr\'esent\'ees.},
  number	= 0808
}

@TechReport{	  jardonnet.09.seminar,
  author	= {Ugo Jardonnet},
  title		= {Image reconstruction},
  titre		= {Reconstruction d'image},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  url		= {http://publications.lrde.epita.fr/200901-Seminar-jardonnet}
		  ,
  urllrde	= {200901-Seminar-jardonnet},
  abstract	= {As part of a partnership with the Gustave Roussy Institut,
		  the LRDE's image processing library Milena, offers an
		  application dedicated to image reconstruction.\\ Different
		  images of the same object but obtained from different
		  modalities have to be processed. First, these images are
		  simplified. Then objects contained by these images are
		  extracted. The final step is to mix information into a
		  unique image.\\ Thereby, the process is composed of several
		  stages: image filtering, segmentation, binarization,
		  multimodal image registration and image reconstruction. The
		  presentation will especially focus on the segmentation
		  part.},
  resume	= {Dans le cadre de son partenariat avec l'institut de
		  canc\'erologie Gustave Roussy, Milena, la biblioth\`eque de
		  traitement d'image du LRDE, propose une cha\^ine de
		  traitement d\'edi\'ee \`a la reconstruction d'image.\\
		  Diff\'erentes images d'un m\^eme objet mais obtenues par
		  diff\'erents modes d'acquisitions, sont trait\'ees.
		  Celles-ci sont d'abord simplifi\'ees. On extrait ensuite
		  les objets qu'elles contiennent. La derni\`ere \'etape
		  consiste \`a construire une image recoupant les
		  informations des diff\'erentes images.\\ Cette cha\^ine se
		  d\'ecrit ainsi en plusieurs \'etapes : filtrage de l'image,
		  segmentation, binarisation, recalage d'image multimodales
		  et reconstruction d'image. L'expos\'e se concentrera
		  essentiellement sur l'etape de segmentation.},
  number	= 0831
}

@TechReport{	  lazzara.07.seminar,
  oldkeys	= {lazzara.ma.07.seminar.boosting.vcsn},
  author	= {Guillame Lazzara and Jimmy Ma},
  title		= {Boosting {V}aucanson},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  abstract	= {The work performed last year underlined the fact that the
		  overall performance issues of Vaucanson could be widely
		  improved by an internal use of hash tables and, more
		  particularly by the Multi Index from the Boost C++ library.
		  We tried to make good use of the new functionalities
		  provided by Boost. It results in the implementation of a
		  new graph structure. We present in this report the
		  different issues implied by these modifications on the
		  graph implementation and we try to answer to the new issues
		  about the genericity of Vaucanson.},
  resume	= {Suite aux s\'eminaires de l'ann\'ee derni\`ere, il en
		  ressort que les performances globales de Vaucanson
		  pouvaient largement \^etre am\'elior\'ees par l'usage de
		  tables de hachage et plus particuli\`erement les Multi
		  Index de la biblioth\`eque Boost. Pour ce s\'eminaire, nous
		  chercherons \`a tirer parti des nouvelles fonctionnalit\'es
		  offertes par Boost. Ceci impliquera l'apparition d'une
		  nouvelle impl\'ementation de graphe. Nous pr\'esenterons au
		  cours de ce s\'eminaire les enjeux induits par ces
		  changements sur l'impl\'ementation et tenterons de
		  r\'epondre au probl\`ematiques soulev\'ees par la
		  g\'en\'ericit\'e de Vaucanson.},
  url		= {http://publications.lrde.epita.fr/200705-Seminar-Lazzara-Ma}
		  ,
  urllrde	= {200705-Seminar-Lazzara-Ma},
  number	= 0700
}

@TechReport{	  lazzara.08.seminar,
  author	= {Guillaume Lazzara},
  title		= {Boosting {Vaucanson}'s genericity},
  titre		= {Booster la g\'en\'ericit\'e de {Vaucanson}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/2007312-Seminar-Lazzara}
		  ,
  urllrde	= {2007312-Seminar-Lazzara},
  resume	= {L'architecture du projet Vaucanson a \'et\'e con\,c{}ue
		  initialement autour du design pattern Element. Ce dernier a
		  l'\'enorme avantage de distinguer \`a la fois les concepts
		  et les impl\'ementations. C'est \`a dire que pour un type
		  d'automate comme les automates bool\'eens, on peut
		  th\'eoriquement avoir plusieurs impl\'ementations qui se
		  c\^otoient dans un m\^eme programme. Malgr\'e toutes ces
		  pr\'ecautions, aujourd'hui, ajouter une nouvelle structure
		  s'av\`ere tr\`es d\'elicat et remet en cause de nombreux
		  points au sein du projet. C'est pour cette raison que
		  durant ce s\'eminaire nous tenterons de r\'epondre \`a ces
		  probl\`emes. Les probl\`emes de performances qu'a pu
		  rencontrer le projet sont \'egalement une bonne motivation
		  pour s'attaquer \`a ce sujet : il est aujourd'hui
		  indispensable de proposer des nouvelles structures plus
		  efficaces, notamment impl\'ement\'ees avec la biblioth\`eque Boost.},
  number	= 0755
}

@TechReport{	  leblanc.07.seminar,
  author	= {Antoine Leblanc},
  title		= {Efficient algorithmic methods for {N}ash equilibria
		  computation},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200706-Seminar-Leblanc},
  urllrde	= {200706-Seminar-Leblanc},
  abstract	= {One of the remaining problems with Nash equilibria is the
		  lack of efficiency of best known algorithms. In general
		  case their worst complexity is $ O(4^{n}) $. Those
		  algorithms are usually old, and aren't likely to be
		  improved. This study focuses first on main algorithms and
		  methods and explains their advantages and their weaknesses.
		  It then introduces a new algorithm developed at the LRDE
		  based on a geometrical approach: a TOP computing method in
		  $ d $ dimensions.},
  resume	= {L'un des principaux probl\`emes rencontr\'es lors de la
		  recherche d'\'equilibres de Nash est le manque
		  d'efficacit\'e des principaux algorithmes. La plupart ont
		  des complexit\'es en pire cas de l'ordre de $ O(4^{n}) $.
		  Il n'est de plus que peu probable de r\'eussir \`a
		  am\'eliorer ces algorithmes, qui sont pour la plupart
		  relativement vieux. Cette \'etude d\'etaille tout d'abord
		  les algorithmes principaux en sp\'ecifiant leurs avantages
		  et inconv\'enients, puis pr\'esente un nouvel algorithme
		  d\'evelopp\'e au LRDE bas\'e sur une approche
		  g\'eom\'etrique : le calcul du TOP en dimension $ d $.},
  number	= 0745
}

@TechReport{	  leblanc.08.seminar,
  author	= {Antoine Leblanc},
  title		= {Alternate Fictitious Play study and implementation},
  titre		= {\'Etude et impl\'ementation du Fictitious Play altern\'e},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200806-Seminar-Leblanc},
  urllrde	= {200806-Seminar-Leblanc},
  resume	= {Le calcul d'un \'equilibre de Nash dans un jeu fini est un
		  probl\`eme d\'emontr\'e PPAD-complet, ce qui signifie qu'il
		  para\^it impossible de trouver une m\'ethode de calcul
		  efficace ; la complexit\'e en pire cas des algorithmes
		  usuels est $ 2^{O(n)} $ pour un jeu de taille $ n $. La
		  recherche en ce domaine s'oriente donc vers le calcul
		  d'\'equilibres approch\'es, \`a savoir des situations
		  v\'erifiant les conditions d'un \'equilibre de Nash \`a $
		  \varepsilon $ pr\`es.

		  L'algorithme du \emph{Fictitious Play} s'inscrit dans cette
		  d\'emarche de recherche. Son principe est simple : \`a
		  chaque it\'eration, chacun des joueurs ``renforce'' celle
		  de ses strat\'egies pures qui est la plus efficace face \`a
		  ses adversaires. Pour certains jeux, cet algorithme
		  converge vers un \'equilibre de Nash, fournissant ainsi un
		  algorithme d'approximation efficace. La convergence ne peut
		  toutefois \^etre prouv\'ee que pour un nombre limit\'e de
		  cas.

		  Pour cette raison, il est int\'eressant d'\'etudier
		  d'autres algorithmes bas\'es sur le \emph{Fictitious Play},
		  afin de trouver d'autres cas de convergence. Nous allons
		  \'etudier ici le \emph{Fictitious Play} altern\'e, dans
		  lequel seul le joueur le plus ``\'eloign\'e'' de son gain
		  optimal renforce sa strat\'egie la plus efficace.},
  abstract	= {Nash equilibria computation in finite games is a problem
		  which is known to be PPAD-complete, which means it
		  currently seems impossible to find an efficient solution ;
		  worst case complexity of well known algorithms is in $
		  2^{0(n)} $ for any game of size $ n $. For this reason,
		  research in this domain currently focuses on $ \varepsilon
		  $-equilibria, situations which approximately satisfy the
		  conditions of a Nash equilibrium.

		  The \emph{Fictitious Play} algorithm fits in this approach.
		  At each iteration of this algorithm, each of the players
		  ``strengthens'' the strategy that has the highest utility
		  in the current context. For some specific game classes this
		  algorithm converges to a Nash equilibrium, therefore
		  providing an efficient approximation method. However,
		  convergence can only be proved for a small amount of game
		  classes.

		  It is therefore useful to study other algorithms (based on
		  \emph{Fictitious Play}) in order to find other convergence
		  cases. In this study, we will focus on the alternate
		  \emph{Fictitious Play} algorithm, in which only one player
		  at a time strengthens one of his strategies : the player
		  which is the ``further'' from his maximum payoff.},
  number	= 0826
}

@TechReport{	  leblanc.08.seminar.comparison,
  author	= {Antoine Leblanc},
  titre		= {Comparaison entre le \emph{Fictitious Play} et le
		  \emph{Fictitious Play Altern\'e} dans le cadre des jeux \`a
		  somme nulle},
  title		= {Efficiency comparison between \emph{Fictitious Play} and
		  \emph{Alternate Fictitious Play} algorithms on the
		  restricted set of zero-sum games},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200812-Seminar-Leblanc},
  urllrde	= {200812-Seminar-Leblanc},
  resume	= {L'algorithme du \emph{Fictitious Play} est un proc\'ed\'e
		  d'apprentissage it\'er\'e utilis\'e dans le cadre de la
		  recherche des \'equilibres de Nash. Son principe est simple
		  : \`a chaque it\'eration, chacun des joueurs ``renforce''
		  celle de ses strat\'egies pures qui est la plus efficace
		  face \`a ses adversaires. Pour certains jeux, cet
		  algorithme converge vers un \'equilibre de Nash,
		  fournissant ainsi un algorithme d'approximation efficace.
		  La convergence ne peut toutefois \^etre prouv\'ee que pour
		  un nombre limit\'e de cas. L'algorithme du \emph{Fictitious
		  Play Altern\'e} (pr\'esent\'e l'ann\'ee derni\`ere) en est
		  une variante dans lequel seul le joueur le plus
		  ``\'eloign\'e'' de son gain optimal renforce sa strat\'egie
		  la plus efficace. Cette \'etude se focalisera sur une
		  comparaison de l'efficacit\'e de ces deux algorithmes dans
		  le cadre des jeux \`a somme nulle et abordera \'egalement
		  les notions de classification des jeux n\'ecessaires \`a la
		  r\'ealisation de cet objectif.},
  abstract	= {The \emph{Fictitious Play} algorithm is an iterate
		  learning process created to compute Nash equilibria. At
		  each iteration of this algorithm, each of the players
		  ``strengthens'' the strategy that has the highest utility
		  in the current context. For some specific game classes this
		  algorithm converges to a Nash equilibrium, therefore
		  providing an efficient approximation method. However,
		  convergence can only be proved for a small amount of game
		  classes. The \emph{Alternate Fictitious Play} algorithm
		  (introduced last year) is a variant in which only one
		  player at a time strengthens one of his strategies : the
		  player which is the ``further'' from his maximum payoff.
		  This study will focus on a comparison of these two
		  approaches on the restricted set of zero-sum games. It will
		  also present the notions of game classification used for
		  this comparison.},
  number	= 0837
}

@TechReport{	  lefortier.08.seminar,
  author	= {Damien Lefortier},
  title		= {Translation of an extended {LTL} into {TBGA} in {S}pot},
  titre		= {Traduction d'une {LTL} \'etendue en {TGBA} dans Spot},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  abstract	= {Spot is centered around the automata approach to model
		  checking. The library can be used to verify that every
		  behavior of a model, a transition-based generalized B\"uchi
		  automata (TGBA), satisfies a given property, expressed
		  using an linear temporal logic (LTL) formula. Spot offers
		  two translation algorithms of LTL into TGBA, one of the two
		  main stages of the approach. We present a new translation
		  into TGBA of a LTL logic which has been extended by adding
		  operators represented by finite automaton. This translation
		  allows Spot to verify properties that were not expressible
		  before.},
  resume	= {Spot repose sur l'approche automate du \emph{model
		  checking}. La biblioth\`eque permet de v\'erifier des
		  propri\'et\'es exprim\'ees en logique temporelle \`a temps
		  lin\'eaire (LTL) sur une mod\'elisation d'un syst\`eme
		  repr\'esent\'ee par un automate de B\"uchi g\'en\'eralis\'e
		  bas\'e sur les transitions (TGBA). Spot propose
		  actuellement deux algorithmes de traduction de LTL en TGBA,
		  une des deux \'etapes principales de l'approche automate.
		  Nous pr\'esentons une nouvelle traduction en TGBA d'une
		  logique LTL qui a \'et\'e \'etendue en y ajoutant des
		  op\'erateurs repr\'esent\'es par des automates finis. Cette
		  traduction permet \`a Spot de v\'erifier des propri\'et\'es
		  qui n'\'etaient pas exprimables auparavant.},
  url		= {http://publications.lrde.epita.fr/200807-Seminar-Lefortier}
		  ,
  urllrde	= {200807-Seminar-Lefortier},
  number	= 0807
}

@TechReport{	  lefortier.09.seminar,
  author	= {Damien Lefortier},
  title		= {Translation of an extended LTL into TBGA in Spot},
  titre		= {Traduction d'une LTL \'etendue en TGBA dans Spot},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  abstract	= {Spot is a model checking library centered around the
		  automata approach, which can be used to verify properties
		  expressed using LTL (Linear Temporal Logic) formul\ae{} on
		  models represented as TGBA (Transition-based Generalized
		  B\"uchi automata). The library offers two translation
		  algorithms from LTL formul\ae{} into TGBA, one of the main
		  stages of the approach. We present an extension of one of
		  these algorithms to an extended LTL where operators are
		  represented by finite automata, allowing Spot to verify
		  properties that were not expressible before. We also
		  present how we could integrate some features of PSL
		  (Property Specification Language) in our extension.},
  resume	= {Spot est une biblioth\`eque de model checking qui permet
		  de v\'erifier des propri\'et\'es exprim\'ees en logique
		  temporelle \`a temps lin\'eaire (LTL) sur des mod\`eles
		  repr\'esent\'es par des automates de B\"uchi
		  g\'en\'eralis\'es bas\'es sur les transitions (TGBA). Spot
		  propose actuellement deux algorithmes de traduction de LTL
		  en TGBA, une des \'etapes principales de l'approche
		  automate. Nous pr\'esentons une nouvelle traduction en TGBA
		  d'une LTL \'etendue dont les op\'erateurs sont
		  repr\'esent\'es par des automates finis, permettant ainsi
		  \`a Spot de v\'erifier des propri\'et\'es qui n'\'etaient
		  pas exprimables auparavant. Nous pr\'esenterons aussi de
		  quelles fa\c cons nous pourrions int\'egrer certaines
		  fonctionnalit\'es de PSL (Property Specification Language) \`a notre extension.},
  url		= {http://publications.lrde.epita.fr/200907-Seminar-Lefortier}
		  ,
  urllrde	= {200907-Seminar-Lefortier}
}

@TechReport{	  lefortier.10.seminar,
  author	= {Damien Lefortier},
  title		= {A new translation from LTL into TGBA in Spot},
  titre		= {Nouvelle traduction de LTL en TGBA dans Spot},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  abstract	= {Spot is a model checking library centered around the
		  automata-theoretic approach, and can be used to verify
		  properties expressed using LTL (Linear Temporal Logic)
		  formul\ae{} on models represented as TGBA (Transition-based
		  Generalized B\"uchi automata). The library offers three
		  algorithms to translate LTL formul\ae{} to TGBA, one of the
		  main stages of the approach. We present a forth translation
		  algorithm introduced by Tauriainen which uses TAA
		  (Transition-based Alternating Automata) as an intermediate
		  representation. We also compare it to the three algorithms
		  already present in Spot.},
  resume	= {Spot est une biblioth\`eque de model checking centr\'ee
		  sur l'approche automate et qui permet de v\'erifier des
		  propri\'et\'es exprim\'ees en logique temporelle \`a temps
		  lin\'eaire (LTL) sur des mod\`eles repr\'esent\'es par des
		  automates de B\"uchi g\'en\'eralis\'es bas\'es sur les
		  transitions (TGBA). Spot propose actuellement trois
		  algorithmes pour traduire des formules LTL en TGBA, une des
		  \'etapes principales de l'approche automate. Nous
		  pr\'esentons une quatri\`eme traduction, introduite par
		  Tauriainen, qui utilise des automates alternants bas\'es
		  sur les transitions (TAA) comme repr\'esentation
		  interm\'ediaire. Nous le comparerons ensuite aux trois
		  algorithmes d\'ej\`a pr\'esent dans Spot.},
  url		= {http://publications.lrde.epita.fr/201001-Seminar-Lefortier}
		  ,
  urllrde	= {201001-Seminar-Lefortier},
  number	= 0912
}

@TechReport{	  legrand.08.seminar,
  author	= {Antoine Legrand},
  title		= {Generalized Linear Discriminant Sequence for Speaker
		  Verification},
  titre		= {Syst\`eme de discriminants lin\'eaires pour la
		  v\'erification du locuteur},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  abstract	= {In speaker verification appplications, GMM models have an
		  important place and have shown good perfomance. Actually,
		  linear discriminant methods using support vector machines
		  (SVM) provide better results. We will focus on a linear
		  disciminant system, the SVM-GLDS. Its uses statistics
		  directly extracted from the speech features to define the
		  recognition model without using Gaussian mixture models
		  (GMMs).\\ We\^all present and compare SVM-GLDS performance
		  to SVM-GMM on NIST speaker evaluation tasks.},
  resume	= {Dans la reconnaissance du locuteur, les mod\`eles GMM
		  occupent une place tr\`es importante dans le
		  d\'eveloppement des syst\`emes performants. Les m\'ethodes
		  de discrimination lin\'eaire \`a base de SVM donnent
		  actuellement de meilleurs r\'esultats. On s'int\'eressera
		  ici \`a un syst\`eme de discriminant lin\'eaire (le
		  SVM-GLDS). Celui-ci utilise directement, sans passer par un
		  mod\`ele GMM, des statistiques issues de l'ensemble des
		  param\`etres de la parole pour d\'efinir le mod\`ele de
		  reconnaissance. On \'evaluera les performances d'un tel
		  syst\`eme sur la base de donn\'ees NIST-SRE en le comparant
		  avec les autres syst\`emes \`a base de SVM-GMM. },
  url		= {http://publications.lrde.epita.fr/200807-Seminar-Legrand},
  urllrde	= {200807-Seminar-Legrand},
  number	= 0819
}

@TechReport{	  lenoir.11.seminar,
  author	= {Victor Lenoir},
  title		= {Voice Activity Detection},
  titre		= {D\'etection de voix},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  url		= {http://publications.lrde.epita.fr/URLLRDE},
  resume	= {La d\'etection de voix a de nombreuses applications. C'est
		  par exemple une \'etape obligatoire avant de faire de la
		  reconnaissance du locuteur. Ce rapport pr\'esente deux
		  diff\'erents types d'algorithmes pour la d\'etection de
		  voix (VAD) : un utilisant des seuils et le second utilisant
		  des m\'elanges de gaussiennes (GMM).\\Les algorithmes
		  propos\'es utilisent des caract\'eristiques calcul\'ees sur
		  des petits intervalles de temps comme par exemple
		  l'\'energie, la monotonie spectrale ou les Mel-Frequency
		  Cepstral Coefficients (MFCC). Les diff\'erents algorithmes
		  de d\'etection de voix sont compar\'es dans diff\'erentes
		  conditions de bruit afin de mettre en \'evidence leur
		  robustesse aux bruits.},
  urllrde	= {URLLRDE}
}

@TechReport{	  leroi.08.seminar,
  author	= {Guillaume Leroi},
  title		= {Synchronized Tranducers},
  titre		= {Transducteurs synchronis\'es},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200712-Seminar-Leroi},
  urllrde	= {200712-Seminar-Leroi},
  resume	= {Lors de cette pr\'esentation, un algorithme de
		  resynchronisation sera d\'ecrit ainsi que son
		  impl\'ementation dans Vaucanson. De plus, des explications
		  sont donn\'ees sur l'ajout des transducteurs a d\'elai
		  born\'e, ainsi que sur les difficult\'es qui peuvent \^etre
		  rencontr\'ees lors de l'extension de la hierarchie de
		  classes de Vaucanson.},
  number	= 0759
}

@TechReport{	  lesaint.07.seminar,
  oldkeys	= {lesaint.07.seminar.xmlproposal},
  author	= {Florian Lesaint},
  title		= {{XML} Proposal and its Application in {V}aucanson},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  abstract	= {The XML Proposal presented at CIAA 2005 (Conference on
		  Implementation and Application of Automata) and updated by
		  Florent Teronnes has some lacks. For example, labels with
		  regular expressions were not clearly defined. Our work has
		  for objective to finalize the proposal of a universal
		  description format for automata to make communication
		  between various tools easier. The second part of our work
		  is to update Vaucanson to support this new format, with a
		  reimplementation of its XML parser. It allowed us to change
		  our parser from a DOM model to a SAX one, reducing memory
		  usage and improving Vaucanson's input performances.},
  resume	= {La proposition XML pr\'esent\'ee \`a CIAA 2005 (Conference
		  on Implementation and Application of Automata) et enrichie
		  depuis par Florent Terrones montrait certaines lacunes. Par
		  exemple, la gestion des expressions rationnelles n'y
		  \'etait pas clairement d\'efinie. Ce travail avait pour but
		  de finaliser la proposition d'un format universel pour la
		  description d'automates afin de faciliter la communication
		  entre les divers outils qui leur sont consacr\'es et de
		  reviser le parser de Vaucanson.},
  url		= {http://publications.lrde.epita.fr/200744-Seminar-Lesaint},
  urllrde	= {200744-Seminar-Lesaint},
  number	= 0744
}

@TechReport{	  lesaint.08.seminar,
  author	= {Florian Lesaint},
  title		= {{FSMXML} and its application in {V}aucanson},
  titre		= {{FSMXML} et son utilisation dans {V}aucanson},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  abstract	= {Last year, we started to work on a new proposal of an XML
		  automata description format, now called FSMXML. This year
		  we are presenting a final version of our work. It takes the
		  form of an \emph{rfc}. FSMXML mainly includes a full
		  generalized regular expressions support, can describe any
		  kind of automaton and has been made easier to support. We
		  redesigned the \textsc{Vaucanson} XML parser structure to
		  get rid of a bad management of dependencies. It is updated
		  according to the \emph{rfc}.},
  resume	= {Nous avions commenc\'e l'ann\'ee derni\`ere \`a travailler
		  sur une nouvelle proposition de format XML de description
		  d'automates, devenu FSMXML. Nous pr\'esentons cette ann\'ee
		  une version aboutie de ce travail sous forme de \emph{rfc}.
		  FSMXML comprend notamment une gestion compl\`ete des
		  expressions rationnelles g\'en\'eralis\'ees, il permet de
		  d\'ecrire n'importe quel type d'automate et sa gestion est
		  facilit\'ee. Nous avons repens\'e la structure du parseur
		  XML de \textsc{Vaucanson} pour s'affranchir d'une mauvaise
		  gestion de d\'ependances et l'avons mise \`a jour
		  conform\'ement \`a la \emph{rfc}.},
  url		= {http://publis.lrde.epita.fr/200806-Seminar-Lesaint},
  urllrde	= {200806-Seminar-Lesaint},
  number	= 0818
}

@TechReport{	  lesaint.08.seminar.syncrelations,
  author	= {Florian Lesaint},
  title		= {Synchronous relations in {V}aucanson},
  titre		= {Les relations synchrones dans {V}aucanson},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  abstract	= {Synchronous rational relations is the largest subfamily of
		  rational relations so far defined that is an effective
		  Boolean algebra. It can be therefore of some interest to
		  provide manipulation tools which might help in their study.
		  With the recently added support of pair-alphabets in
		  Vaucanson, we suggest a new approach to deal with
		  synchronous rational relations represented as
		  letter-to-letter transducers and provide the necessary
		  tools to work with them.},
  resume	= {La famille des relations rationnelles synchrones est la
		  plus grande famille de relations rationnelles, d\'efinie
		  jusqu'ici, qui est une alg\`ebre de Boole effective.
		  Fournir des outils permettant de les manipuler peut donc
		  s'av\'erer int\'eressant pour leur \'etude. Le r\'ecent
		  support des alphabets de paires dans Vaucanson nous permet
		  une nouvelle approche pour travailler avec les relations
		  rationnelles synchrones, repr\'esent\'ees par des
		  transducteurs lettre \`a lettre, pour lesquels nous
		  fournissons les outils n\'ecessaires \`a leur manipulation.},
  url		= {http://publications.lrde.epita.fr/200901-Seminar-Lesaint},
  urllrde	= {200901-Seminar-Lesaint},
  number	= 0833
}

@TechReport{	  levi.11.seminar,
  author	= {Coddy Levi},
  title		= {{Inverse Video extraction in Scribo}},
  titre		= {Extraction de l'inverse video dans SCRIBO.},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  abstract	= {Text in document images that is subject to extraction
		  through document analysis can be present in two forms: dark
		  text over light background (conventional form) or light
		  text over dark background (Inverse Video). This report
		  introduces the problematic of extracting inverse video text
		  using an existing toolchain, its integration in Scribo, the
		  problems it involves and solutions to better results that
		  we have explored.},
  resume	= {Le texte sujet \`a extraction via l'analyse de document
		  peut \^etre pr\'esent dans deux formes : fonc\'e sur fond
		  clair ou clair sur fond fonc\'e, appel\'e Inverse Video. Ce
		  rapport explique les probl\'ematiques li\'ees \`a
		  l'extraction de l'inverse video dans Scribo en utilisant la
		  cha\^ine de traitement d\'ej\`a existante, les probl\`emes
		  ainsi introduits et les pistes explor\'ees pour
		  l'am\'elioration des r\'esultats.},
  url		= {http://publications.lrde.epita.fr/201107-Seminar-Levi},
  urllrde	= {201107-Seminar-Levi},
  number	= 1114
}

@TechReport{	  lobry.11.seminar,
  author	= {Sylvain Lobry},
  title		= {{Scribo: Disambiguation of lines superimposement}},
  titre		= {D\'esambigu\"isation de la superposition de lignes.},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  abstract	= {This report aims to explain and resolve a common problem
		  that arise when handling inverse video (light color on dark
		  background) : line collision. We will explain how to make a
		  choice between two lines (one in inverse video, the other
		  in normal mode) when they are superimposed by considering
		  criteria and by balancing them.},
  resume	= {Lorsque l'on essaye d'extraire du texte en inverse vid\'eo
		  (couleur claire sur fond fonc\'e), nous verrons lors de la
		  pr\'esentation de Coddy Levi que de nombreux probl\`emes
		  surgissent. Le plus courant d'entre eux est la
		  superposition entre ce texte en inverse vid\'eo, et celui
		  en couleur fonc\'ee sur clair. Nous montrerons donc dans
		  cette pr\'esentation comment faire un choix entre ces
		  lignes en superposition, en consid\'erant diff\'erents
		  crit\`eres et en les pond\'erant.},
  url		= {http://publications.lrde.epita.fr/201107-Seminar-Lobry},
  urllrde	= {201107-Seminar-Lobry},
  number	= 1110
}

@TechReport{	  ma.08.seminar,
  author	= {Jimmy Ma},
  title		= {Boosting {V}aucanson's Iterator},
  titre		= {Booster les it\'erateurs de {V}aucanson},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  abstract	= {Vaucanson is a generic finite state machine manipulation
		  platform. We have based our genericity on the ability to
		  not only support various types of automata, but also to use
		  different data structures to represent them. In its current
		  state, we have various techniques to iterate over sets of
		  transitions, however, none of them is really independent of
		  the data structures. To overcome this problem, we have
		  integrated the design pattern Iterator. Our goal is to
		  assess the improvements given by this method in terms of
		  performance and code writing.},
  resume	= {Vaucanson est une biblioth\`eque g\'en\'erique de
		  manipulation d'automates. Le c\oe{}ur de sa
		  g\'en\'ericit\'e r\'eside dans le support de types
		  d'automates vari\'es mais aussi sa capacit\'e \`a s'appuyer
		  sur diff\'erentes structures de donn\'ees. Actuellement,
		  nous avons diff\'erentes mani\`eres de manipuler des
		  transitions. Cependant, aucune d'entre elles n'est
		  r\'eellement ind\'ependante de la structure de donn\'ees
		  utilis\'ee. Afin de pallier cela, nous allons nous tourner
		  vers le design pattern Iterator. Nous \'evaluerons l'impact
		  de ce design pattern sur les performances et sur
		  l'utilisation de la biblioth\`eque en termes d'\'ecriture d'algorithmes.},
  url		= {http://publis.lrde.epita.fr/200806-Seminar-Ma},
  urllrde	= {200806-Seminar-Ma},
  number	= 0820
}

@TechReport{	  ma.09.seminar,
  author	= {Jimmy Ma},
  title		= {{A}utomata in {N}atural {L}anguage {P}rocessing},
  titre		= {Les automates en traitement automatique des langues
		  naturelles},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  abstract	= {Vaucanson has been designed to satisfy the needs of the
		  automaticians. There are, however, other fields where
		  automata are widely used. This prospective report will
		  focus on linguistics, and more precisely the automata needs
		  of the natural language processing community since the
		  applications differ from our usual ones. This way, we will
		  be able to assess our range of applicability and usability.
		  First, we will explore the different domains and detail the
		  various needs. Then, we will be able to evaluate whether or
		  not Vaucanson is usable for those domains and, finally,
		  discuss some potential work leads.},
  resume	= {Jusqu'\`a pr\'esent, Vaucanson s'adressait essentiellement
		  \`a la communaut\'e des automaticiens. Cependant, il existe
		  d'autres domaines o\`u les automates sont utilis\'es. Dans
		  ce rapport prospectif, nous nous orienterons vers la
		  communaut\'e des linguistes et, plus pr\'ecis\'ement, vers
		  le domaine du traitement automatique des langues naturelles
		  car les besoins de ce domaine diff\`erent de nos
		  utilisations habituelles. Nous observerons diverses
		  sp\'ecialit\'es et dresserons un bilan des besoins en
		  automates. Ainsi, nous pourrons \'evaluer l'ad\'equation de
		  Vaucanson pour ce domaine et en d\'egager des pistes
		  d'\'evolutions \'eventuelles pour le projet.},
  url		= {http://publis.lrde.epita.fr/200901-Seminar-Ma},
  urllrde	= {200901-Seminar-Ma},
  number	= 0834
}

@TechReport{	  marquegnies.10.seminar,
  author	= {Julien Marquegnies},
  title		= {Dematerialization Tools in SCRIBO},
  titre		= {Outils pour la d\'emat\'erialisation dans SCRIBO},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  abstract	= {SCRIBO, for Semi-automatic and Collaborative Retrieval of
		  Information Based on Ontologies, is a document image
		  analysis and semi-automatic analysis project aiming to
		  establish algorithms and collaborative tools in order to
		  extract knowledge from texts and images.

		  The extraction of the different structures of a digitalized
		  document is based on the setup of a processing chain
		  composed of crucial steps to optimize the quality of the
		  rendering. The deskewing of images, prior to the processing
		  chain, is a necessary step that corrects a possible angle
		  due to the digitization of the document. Moreover, the
		  extraction and the study of the characters composing the
		  text, like the average color, the average boldness or the
		  skeleton, not only enables a reconstitution of the text as
		  accurate as possible, but also prepares this one for the
		  OCR.

		  Thereby, we will first introduce an algorithm providing a
		  quick detection of the skew angle of a document for little
		  angles, and then the study conducted to extrct different
		  character features.},
  resume	= {SCRIBO, pour Semi-automatic and Collaborative Retrieval of
		  Information Based on Ontologies, est un projet de
		  d\'emat\'erialisation ayant pour finalit\'e la mise en
		  place d'algorithmes visant \`a extraire des connaissances
		  \`a partir de textes et d'images.

		  Le redressement de l'image, en amont de la cha\^ine de
		  traitements, est une phase n\'ecessaire afin de corriger
		  l'\'eventuel angle d\^u \`a la num\'erisation du document.
		  De plus, l'extraction et l'\'etude des informations des
		  caract\`eres composant le texte permet non seulement de
		  r\'ealiser une reconstitution la plus fid\`ele possible du
		  texte mais \'egalement de pr\'eparer ce dernier \`a son
		  passage dans l'OCR.

		  Ainsi, nous pr\'esenterons dans un premier temps un
		  algorithme permettant de d\'etecter l'inclinaison d'un
		  document pour de petits angles, puis l'\'etude men\'ee sur
		  l'extraction des diff\'erentes caract\'eristiques des caract\`eres.}
}

@TechReport{	  marquegnies.11.seminar,
  author	= {Julien Marquegnies},
  title		= {Document layout analysis in SCRIBO},
  titre		= {Analyse de la mise en page d'un document dans SCRIBO},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  number	= 1102,
  url		= {http://publications.lrde.epita.fr/201107-Seminar-Marquegnies}
		  ,
  urllrde	= {201107-Seminar-Marquegnies},
  abstract	= {The extraction of the different structures of a
		  digitalized document is based on the setup of a processing
		  chain composed of crucial steps to optimize the quality of
		  the rendering. The document layout analysis, meaning the
		  extraction of lines structures, paragraphs, constitutes the
		  core of the processing because the rendering is closely
		  correlated with the text used to fed the OCR system.

		  Thereby, we will introduce a hybrid document layout
		  analysis approach developed under the SCRIBO project.},
  resume	= {L'extraction des diff\'erentes structures d'un document
		  num\'eris\'e se base sur la mise en place d'une cha\^ine de
		  traitements constitu\'ee d'un certain nombre d'\'etapes
		  primordiales afin d'optimiser la qualit\'e du rendu final.
		  L'\'etude de la mise en page du document, \`a savoir la
		  localisation des lignes de texte et des paragraphes,
		  constitue le coeur m\^eme de la cha\^ine puisque le rendu
		  obtenu est \'etroitement corr\'el\'e avec les zones de
		  texte donn\'ees en entr\'ee \`a l'OCR.

		  Ainsi, nous pr\'esenterons une m\'ethode hybride d'analyse
		  de mise en page d\'evelopp\'ee dans le cadre du projet SCRIBO.}
}

@TechReport{	  marquegnies.12.seminar,
  author	= {Julien Marquegnies},
  title		= {A comparative study of image invariants for text / non-text classification},
  titre		= {Etude comparative d'invariants de forme pour la
                  classification texte / non texte},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2012,
  number	= 1115,
  url		= {http://publications.lrde.epita.fr/201201-Seminar-Marquegnies}
		  ,
  urllrde	= {201201-Seminar-Marquegnies},
  abstract	= {Image recognition main objective is to enable
                  computers to recognize shapes without needing any
                  human intervention. However, one problem in this
                  field is automatic recognition regardless to image
                  transformations like rotation or scales
                  changes. Image invariants based on moments have
                  received a particular attention since they respect
                  fully or partially the constraints listed above.

                  Various shape-based invariant algorithms are popular
                  in Document Image Analysis and especially for
                  Optical Character Recognition systems since they
                  provide relevant features used to differentiate
                  characters. Nevertheless, they also find an
                  interesting application in Document Layout Analysis
                  by providing information that can be used to
                  distinguish text from non-text elements.

                  Thus, we will introduce the concepts of image
                  invariants and evaluate the performances of six
                  state-of-the-art shape-based image invariants for
                  text / non-text classification. An attempt of an
                  image invariant algorithm inspired from the
                  principle of compressive sensing is also offered.},
  resume	= {L'objectif principal de la reconnaissance des
                  formes est de permettre aux ordinateurs de
                  reconnatre des \'el\'ements sans n\'ecessiter une
                  quelconque intervention ext\'erieure. Cependant, un
                  problme r\'ecurrent provient des transformations
                  telles la translation ou la rotation qui peuvent
                  \^etre appliqu\'ees \`a l'image d'origine. Ainsi,
                  diff\'erents moments calcul\'es sur l'image ont
                  suscit\'e un int\'er\^et particulier du fait de leur
                  invariance \`a plusieurs des transformations rencontr\'ees.

                  Un certain nombre d'algorithmes bas\'es sur les
                  invariants de forme sont populaires en analyse
                  d'image de documents et en particulier en ce qui
                  concerne les systmes de reconnaissance optique de
                  caractres puisqu'ils offrent une caract\'erisation
                  pertinente permettant la diff\'erenciation des
                  lettres. Ils trouvent \'egalement un int\'er\^et
                  dans l'analyse de la mise en page de documents en
                  fournissant des informations qui peuvent \^etre
                  utilis\'ees pour diff\'erencier les \'el\'ements
                  textuels des \'el\'ements non textuels.

                  Ainsi, nous pr\'esenterons le concept de moments
                  ainsi que l'\'evaluation de six invariants de forme
                  issus de l'\'etat de l'art dans le cadre de la
                  classification texte / non-texte. Un algorithme
                  d'invariants de forme inspir\'e du principe du
                  compressive sensing est \'egalement propos\'e.}
}

@TechReport{	  melin.07.seminar,
  oldkeys	= {melin.ramakichenin.07.seminar},
  author	= {Charles Melin and Julien Ramakichenin},
  title		= {{LRDE}'s Speaker Verification Framework},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200706-Seminar-Ramakichenin-Melin-Report}
		  ,
  urllrde	= {200706-Seminar-Ramakichenin-Melin-Report},
  number	= 0706
}

@TechReport{	  moreira.11.seminar,
  author	= {David Moreira},
  title		= {Implementing rational semiring},
  titre		= {Impl\'ementation du corps des (nombres) rationnels},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  url		= {http://publications.lrde.epita.fr/201107-Seminar-Moreira},
  urllrde	= {201107-Seminar-Moreira},
  number	= 1107,
  abstract	= { Vaucanson is a finite state machine manipulation platform
		  for automata and transducers. Usage highlighted the overly
		  complex interface for the automaton manipulation. For the
		  past two years, active development has been undertaken to
		  introduce the concept of automaton kind. Today, a part of
		  the new interface have been implemented and the work on the
		  core of still Vaucanson 1.4 in a instable state. First,
		  this report show the work done for Vaucanson 1.4, then on
		  the work undertaken to make Vaucanson 2.0 stable. },
  resume	= { Vaucanson est une plateforme de manipulation d'automates
		  finis et de transducteurs dont l'interface s'est montr\'ee
		  trop complexe. Pendant les deux derni\`eres ann\'ees, des
		  travaux ont \'et\'e entrepris afin d'introduire le concept
		  de kind d'un automate dans la biblioth\`eque. Aujourd'hui,
		  une partie de la nouvelle interface a \'et\'e implement\'ee
		  et le travail sur le c\oe ur a laiss\'e Vaucanson 1.4 dans
		  un \'etat instable. Cette pr\'esentation montrera dans un
		  premier temps le travail effectu\'e pour Vaucanson 1.4,
		  puis sur les travaux entrepris afin de rendre stable Vaucanson 2.0. }
}

@TechReport{	  moulard.06.seminar,
  author	= {Thomas Moulard},
  title		= {Conception of a static oriented language: an overview of
		  {Scool}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  urllrde	= {200607-Hocquet-Moulard},
  year		= 2006,
  number	= 0610
}

@TechReport{	  moulard.07.seminar,
  oldkeys	= {moulard.07.seminar.scoop.container},
  author	= {Thomas Moulard},
  title		= {{C++} container library with the {SCOOP} paradigm},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  number	= 0710,
  url		= {http://publications.lrde.epita.fr/200706-Seminar-Moulard},
  urllrde	= {200706-Seminar-Moulard}
}

@TechReport{	  moulard.08.seminar,
  author	= {Thomas Moulard},
  title		= {An overview of {Scoop}, a static object-oriented
		  paradigm},
  titre		= {Une introduction \`a {Scoop}, un paradigme \Cxx orient\'e
		  objet},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200712-Seminar-Moulard},
  urllrde	= {200712-Seminar-Moulard},
  abstract	= {\Cxx has achieved to support classic object-oriented and
		  generic programming, but some modelisation problems remain
		  recurrent and difficult to solve. Scoop is a static
		  Object-Oriented paradigm. The paradigm provides virtual
		  methods, argument covariance, virtual types and
		  multi-methods statically typed without extending the
		  language. Scoop uses its own \Cxx library in order to make
		  easier to design a library with this paradigm.},
  resume	= {\Cxx a r\'eussi \`a supporter \`a la fois la programmation
		  orient\'e objet classique et la programmation
		  g\'en\'erique, cependant certains probl\`emes r\'ecurrents
		  restent toujours difficiles \`a r\'esoudre. Scoop est un
		  paradigme orient\'e objet. Il fournit des m\'ethodes
		  virtuelles, les arguments covariants, les types virtuels et
		  les multi-m\'ethodes typ\'ees statiquement sans avoir
		  besoin d'\'etendre le langage. Scoop utilise sa propre
		  biblioth\`eque \Cxx pour facilier la conception d'une
		  biblioth\`eque utilisant ce paradigme.},
  number	= 0761
}

@TechReport{	  neri.07.seminar,
  oldkeys	= {neri.07.seminar.learning},
  author	= {Neri Nicolas},
  title		= {Learning models for model-checking},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/20070509-Seminar-NicolasNeri-Report}
		  ,
  urllrde	= {20070509-Seminar-NicolasNeri-Report},
  number	= 0704
}

@TechReport{	  neri.08.seminar,
  author	= {Nicolas Neri},
  title		= {Transfinite Chomp},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200801-Seminar-Neri},
  urllrde	= {200801-Seminar-Neri},
  abstract	= {FILL ME},
  resume	= {Dans ce rapport technique, nous nous attardons sur le jeu
		  de la tablette de chocolat. On dispose d'une tablette de
		  chocolat dont le carr\'e inf\'erieur gauche est
		  empoisonn\'e. Les joueurs jouent \`a tour de r\^ole. Un
		  coup consiste \`a choisir un carr\'e de chocolat et \`a le
		  manger ainsi que tous les carr\'es qui sont \`a sa droite
		  et au dessus de lui. Le joueur qui mange le carr\'e
		  empoisonn\'e perd la partie. Dans cet expos\'e, nous nous
		  int\'eresserons particuli\`erement au cas o\`u les
		  dimensions du jeu sont de classe cardinale infinie. On
		  pr\'esentera \'egalement, pour une meilleure
		  compr\'ehension, les nombres ordinaux et leur ordre associ\'e.},
  number	= 0758
}

@TechReport{	  o-connor.04.seminar,
  oldkeys	= {o-connor.transducer.04.seminar},
  author	= {Sarah O'Connor},
  title		= {Implementation of transducers in {V}aucanson},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2004,
  urllrde	= {20040623-Seminar-SarahOConnor-transducers-Slides},
  number	= 0412
}

@TechReport{	  odou.05.seminar,
  oldkeys	= {odou.taxonomy.05.seminar},
  author	= {Simon Odou},
  title		= {Images taxonomy and modeling},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2005,
  urllrde	= {200506-Seminar-Odou},
  number	= 0501
}

@TechReport{	  ordy.08.seminar,
  author	= {Vincent Ordy},
  title		= {Implementing a {C++} extension with {Transformers}:
		  \texttt{class namespace}},
  titre		= {Impl\'ementation d'une extension du {C++} dans
		  {Transformers}: \texttt{class namespace}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  astract	= {C++ classes are closed, such that once a class definition
		  is ended, nothing can be added to it. But most of the time,
		  programmers are used to distinguish method definition from
		  method implementation. As a consequence, using
		  fully-qualified name of method names and return types are
		  needed, which is repetitive and tedious, especially with
		  template and nested classes. We propose extending C++
		  grammar with a namespace-like syntax in order to define
		  easily member functions and static data members already
		  declared in the class definition. This work will be based
		  on Tranformers' C++ grammar and transformation rules in
		  Stratego Language.},
  resume	= {Les classes en C++ sont ferm\'ees, c'est-\`a-dire qu'on ne
		  peut rien leur ajouter une fois leur d\'efinition
		  termin\'ee. Or, la plupart du temps, les programmeurs
		  s\'eparent la d\'efinition de l'impl\'ementation, ce qui
		  oblige \`a utiliser une syntaxe r\'ep\'etitive, en
		  particulier dans le cas de patrons de classes ou de classes
		  imbriqu\'ees. On se propose donc de faire une extension de
		  la grammaire du C++ permettant via une syntaxe proche de
		  celle des namespaces de d\'efinir plus ais\'ement des
		  m\'ethodes ou attributs statiques d\'ej\`a d\'eclar\'es
		  dans la d\'efinition de la classe. Dans ce but, nous
		  utiliserons la grammaire du C++ impl\'ement\'ee dans
		  Transformers, et des transformations \'ecrites en Stratego.},
  url		= {http://publications.lrde.epita.fr/200807-Seminar-Ordy},
  urllrde	= {200807-Seminar-Ordy},
  number	= 0813
}

@TechReport{	  ordy.09.seminar,
  author	= {Vincent Ordy},
  title		= {Adding {Contracts} to {C++} with {Transformers}},
  titre		= {Ajout de la programmation par contrats au {C++} avec
		  {Transformers}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  abstract	= {Contract programming is a paradigm that allows developers
		  to ensure that some conditions are satisfied when a
		  function is called (\emph{preconditions}), or when it
		  returns (\emph{postconditions}). It makes debugging easier
		  and it is a good way to document what a function accepts as
		  argument or ensures on the result. In oriented-object
		  languages, it is also possible to check a set of conditions
		  on every call and return of any member function of a class
		  (\emph{class invariants}), and conditions are inherited
		  from parent classes.

		  The Transformers project aims at providing source to source
		  transformations on C and C++ sources. A C extension to
		  support contracts in C has already been written, when C++
		  parsing wasn't working yet.

		  We will show how to write a C++ grammar extension to bring
		  contracts in the C++ with the Transformers project, and
		  then how to transform this extended C++ into standard C++.},
  resume	= {La programmation par contrats est un paradigme permettant
		  de r\'eduire le temps de d\'ebogage des programmes, en
		  sp\'ecifiant des conditions qui doivent \^etre
		  v\'erifi\'ees \`a l'entr\'ee d'une fonction (\emph
		  {pr\'econditions}) ou \`a sa sortie (\emph
		  {postconditions}). Dans les languages orient\'es objet, il
		  est \'egalement possible de v\'erifier un ensemble de
		  contraintes \`a chaque appel ou sortie d'une fonction
		  membre (\emph{invariants de classe}), et les conditions
		  sont h\'erit\'ees \`a partir des classes parentes.

		  Le projet Transformers a pour but de faire de la
		  transformation source \`a source sur des sources C et C++.
		  Une extension pour introduire les contrats dans le C a
		  d\'ej\`a \'et\'e \'ecrite alors que l'analyse syntaxique du
		  C++ n'\'etait pas encore fonctionnelle.

		  Nous allons montrer comment \'ecrire une extension de la
		  grammaire du C++ dans le projet Transformers pour
		  introduire le principe de contrat dans le C++, puis
		  transformer le code \'etendu en C++ standard.},
  url		= {http://publications.lrde.epita.fr/200905-Seminar-Ordy},
  urllrde	= {200905-Seminar-Ordy},
  number	= 0901
}

@TechReport{	  ordy.10.seminar,
  author	= {Vincent Ordy},
  title		= {Study and Analysis of {C++} Extension Conception with
		  {Transformers}},
  titre		= {\'Etude et analyse de l'\'ecriture d'extensions du C++
		  gr\^ace \`a {Transformers}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  abstract	= { The Transformers project aims at providing source to
		  source transformations for C and C++ languages. This
		  consists in parsing the input source, a C/C++ source code
		  extended to accept new syntactic rules. The input code is
		  then transformed into standard C/C++. This is similar to
		  the process used by the C++ ancestor, ``C with classes'',
		  which was an extension of C and which was transformed into
		  C before being compiled.

		  We will show how to write an extension of the C++ grammar
		  using the Transformers project, and to transform the
		  extended C++ input into standard C++. For this purpose, we
		  will use extensions that have already been implemented
		  (ContractC++, class-namespaces) as examples. We will
		  analyse to what extent the technologies like attribute
		  grammars used in Transformers help us. },
  resume	= { Le projet Transformers permet de faire de la
		  transformation source \`a source pour les languages C et
		  C++. Le but est de pouvoir effectuer une analyse syntaxique
		  d'un langage d'entr\'ee, du C ou C++ \'etendu pour accepter
		  de nouveaux \'el\'ements syntaxiques, qui seront ensuite
		  transform\'es en C/C++ standard de la m\^eme mani\`ere que
		  \og{}C avec classes\fg{}, anc\^etre du C++, \'etait d'abord
		  transform\'e en C avant d'\^etre compil\'e.

		  Nous allons expliquer comment \'ecrire une extension de la
		  grammaire du C++ gr\^ace au projet Transformers puis
		  transformer le code \'etendu en code standard, en nous
		  appuyant sur des exemples d'extensions d\'ej\`a \'ecrites
		  (ContractC++, class-namespaces). Nous montrerons les
		  avantages et inconv\'enients des technologies utilis\'ees
		  par Transformers comme les grammaires attribu\'ees.},
  url		= {http://publications.lrde.epita.fr/201001-Seminar-Ordy},
  urllrde	= {201001-Seminar-Ordy},
  number	= 0913
}

@TechReport{	  parutto.11.seminar,
  author	= {Pierre Parutto},
  title		= {Improving degeneralization in Spot},
  titre		= {Am\'elioration de la d\'eg\'en\'eralisation dans Spot},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  url		= {http://publications.lrde.epita.fr/201107-Seminar-Parutto},
  urllrde	= {201107-Seminar-Parutto},
  abstract	= {Spot is a model checking library developed at the LRDE.
		  Its strengh is to be based on Transition Based generalized
		  {B\"u}chi Automaton (TGBA), instead of Transition Based
		  {B\"u}chi Automaton (TBA) widely used in other model
		  checkers. TGBAs allows us to create a very small automaton
		  representing a given formula hence making the whole model
		  checking process faster. Spot emphasizes on the usability
		  and customization of its tools, a great concern is to be
		  able to interface Spot with other programs.
		  Degeneralization the process of transforming a TGBA into a
		  TBA, is central in this view. We present in this report an
		  analysis of the tools already present in Spot for
		  degeneralization and we proposes some way to improve them.},
  resume	= {Spot est une biblioth\`eque de model checking develop\'ee
		  au LRDE. Sa force est d'utiliser les Automates de {B\"u}chi
		  Generalis\'es bas\'es sur les transitions (TGBA), plut\^ot
		  que les Automates de {B\"u}chi bas\'es sur les Transitions
		  (TBA) tr\`es utilis\'es dans les autres model checkers. Les
		  TGBA nous permettent de produire des automates tr\`es
		  petits repr\'esentant une formule rendant toutes les
		  \'etapes suivantes du model checking plus rapide. Comme
		  Spot met l'accent sur l'utilisabilit\'e et la
		  personnalisation des outils, une attention particuli\`ere
		  est port\'ee sur l'interfa\c{c}age avec d'autres
		  programmes. La question de transformer un TGBA en TBA
		  (appel\'e d\'egeneralization) sans perdre en performance
		  est donc centrale. Cette pr\'esentation a pour but de
		  montrer une analyse des outils de d\'eg\'en\'eralisation
		  pr\'esents dans Spot et de proposer des moyens pour les am\'eliorer.},
  number	= 1111
}

@TechReport{	  pierron.07.seminar,
  oldkeys	= {pierron.07.seminar.formal.def},
  author	= {Nicolas Pierron},
  title		= {Formal Definition of the Disambiguation with Attribute
		  Grammars},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200706-Seminar-Pierron},
  urllrde	= {200706-Seminar-Pierron},
  astract	= {The current problem of the disambiguation in Transformers
		  with attribute grammars is that no-one has a proof that
		  allows certification of this approach. The current use of
		  attribute grammars for the disambiguation of C and a part
		  of C++ lets us think that this method is correct. In order
		  to remove any doubt, a definition and a formalization of
		  our approach are necessary. This work is split in two
		  parts. The first one relates to the proof of the validity
		  of the approach used in Transformers. The second one is
		  devoted to the correction and the re-development of the
		  existing tools according to the model defined.},
  resume	= {Le probl\`eme actuel de la d\'esambigu\"isation dans
		  Transformers avec des grammaires attribu\'ees est que l'on
		  ne poss\`ede pas de preuve permettant de certifier cette
		  approche. L'usage actuel des grammaires attribu\'ees pour
		  la d\'esambigu\"isation du C et d'une partie du C++ laisse
		  \`a penser que cette m\'ethode est correcte. Afin de
		  supprimer tout doute, une d\'efinition et une formalisation
		  de notre approche est n\'ecessaire. Ce travail comporte est
		  divis\'e en deux parties. La premi\`ere porte sur la preuve
		  de la validit\'e de l'approche utilis\'ee dans
		  Transformers. La seconde est consacr\'ee \`a la correction
		  et au re-d\'eveloppement des outils existants suivant le mod\`ele d\'efini.},
  number	= 0702
}

@TechReport{	  pierron.08.seminar,
  author	= {Akim Demaille and Renaud Durlin and Nicolas Pierron and
		  Beno\^it Sigoure},
  title		= {Automatic Attribute Propagation for Modular Attribute
		  Grammars},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200801-Seminar-Pierron},
  urllrde	= {200801-Seminar-Pierron},
  astract	= {Attribute grammars are well suited to describe (parts of)
		  the semantics of programming languages: hooked on the
		  syntactic production rules, they allow to express local
		  relations that are later bound globally by a generic
		  evaluator. However they fall short when working on large
		  and complex languages. First attributes that are virtually
		  needed everywhere need to be propagated by every single
		  production rule. Second, this constraint hinders
		  modularity, since adding a syntactic extension might
		  require the propagation of new attributes in the rest of
		  the language. This paper shows how to solve these problems
		  by introducing a technique to automatically propagate
		  attributes by completing the set of semantic rules. We
		  formally define the propagation constraints such that it is
		  optimized to avoid unnecessary addition of semantic rules.
		  Attribute grammars are thus made more maintainable, modular
		  and easier to use.},
  resume	= {Les grammaires attribu\'ees sont plus adapt\'ees pour
		  d\'ecrire (des parties de) la s\'emantique d'un langage de
		  programmation : accroch\'ees sur les r\`egles de production
		  syntaxique, elles permettent d'exprimer des relations
		  locales qui sont par la suite li\'ees entre elles
		  globalement par un \'evaluateur g\'en\'erique. Cependant
		  elles ne passent pas \`a l'\'echelle quand on travaille
		  avec des langages volumineux et complexes. Premi\`erement
		  les attributs qui sont requis quasiment partout ont besoin
		  d'\^etre v\'ehicul\'es par chaque r\`egle de production.
		  Deuxi\`emement, ces contraintes cassent la modularit\'e car
		  le fait d'\'etendre une grammaire n\'ecessite la
		  propagation des nouveaux attributs \`a travers le reste du
		  langage. Ce papier montre comment r\'esoudre ces
		  probl\`emes en introduisant un syst\`eme de propagation
		  automatique des attributs qui compl\`ete l'ensemble des
		  r\`egles s\'emantiques. Nous avons d\'efini formellement
		  les contraintes de propagations de mani\`ere optimis\'ee
		  afin d'\'eviter l'ajout de r\`egles s\'emantiques inutiles.
		  Ainsi les grammaires attribu\'ees sont devenus plus
		  maintenables, modulaires et facile \`a utiliser.},
  number	= 0801
}

@TechReport{	  pouchet.04.seminar.gui,
  oldkeys	= {pouchet.vgi.04.seminar},
  author	= {Louis-Noel Pouch\"et},
  title		= {D\'eveloppement d'une interface graphique pour
		  {V}aucanson},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2004,
  note		= {Core curriculum internship of EPITA},
  urllrde	= {FIXME}
}

@TechReport{	  pouchet.04.seminar.interpreter,
  oldkeys	= {pouchet.vcsn-interpretor.04.seminar},
  author	= {Louis-No\"el Pouchet},
  title		= {An interpreter for {V}aucanson},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2004,
  urllrde	= {20040623-Seminar-Pouchet-Vaucanson-Interpreter-Report},
  number	= 0413
}

@TechReport{	  querol.07.seminar,
  author	= {Geoffroy Querol},
  title		= {Speaker recognition evaluation: selective approaches and
		  fusion},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200705-Seminar-Querol},
  urllrde	= {200705-Seminar-Querol},
  number	= 0707
}

@TechReport{	  querol.08.seminar,
  author	= {Geoffroy Querol},
  title		= {{SVM-MLLR} for multi-speaker verification systems score
		  fusion},
  titre		= {{SVM-MLLR} et fusion pour la v\'erification du locuteur},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200756-Seminar-Querol},
  urllrde	= {200756-Seminar-Querol},
  resume	= {Afin d'am\'eliorer la performance globale des syst\`emes
		  de v\'erification du locuteur, il faut diversifier les
		  approches. Le but de ce travail est d'\'etudier les
		  performances d'un syst\`eme SVM-MLLR. Cette m\'ethode se
		  base sur la construction, \`a partir du mod\`ele du monde,
		  d'une transformation lin\'eaire des vecteurs moyennes (mean
		  supervectors) maximisant la vraisemblance du mod\`ele
		  transform\'e par rapport aux donn\'ees locuteur. On
		  \'evaluera deux approches diff\'erentes : Dans la
		  premi\`ere, on utilisera directement le logarithme du
		  rapport de vraisemblance (GMM-MLLR). Dans une deuxi\`eme
		  exp\'erimentation, on utilisera les SVMs pour \'evaluer les
		  scores de d\'ecision. La derni\`ere \'etape consiste \`a
		  valuer l'apport d'une m\'ethode de compensation du canal
		  (NAP: Nuisance Attribute Projection) sur les performances
		  de ce syst\`eme). Une fusion des scores avec d'autres
		  syst\`emes GMM sera \'etudi\'ee. Une fusion au niveau des
		  noyaux sera quand \`a elle pr\'esent\'ee par Charles-Alban.
		  Tous les tests vont \^etre men\'es sur les deux bases de
		  donn\'ees NIST-SRE 2005 et 2006 all trials.},
  number	= 0756
}

@TechReport{	  queze.07.seminar,
  oldkeys	= {queze.07.seminar.tools.ag.manipulation},
  author	= {Florian Qu\`eze},
  title		= {Tools for Attribute Grammars manipulation in
		  Transformers},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200706-Seminar-Queze},
  urllrde	= {200706-Seminar-Queze},
  number	= 0747
}

@TechReport{	  queze.08.seminar,
  author	= {Florian Qu\`eze},
  title		= {C++ Program Slicing with {Transformers}},
  titre		= {D\'ecoupage de programme C++ avec {Transformers}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publis.lrde.epita.fr/200806-Seminar-Queze},
  urllrde	= {200806-Seminar-Queze},
  abstract	= {Transformers is a C++ manipulation framework built on
		  Stratego/XT. Program Slicing is an important field of
		  program transformation. We will explain what Program
		  Slicing is, give a quick overview of various aspects of
		  Program Slicing and show how Transformers can be turned
		  into a C++ Program Slicing tool.},
  resume	= {Transformers est un emsemble d'outils bas\'es sur
		  Stratego/XT permettant la manipulation de programmes C++.
		  Le d\'ecoupage de programmes est un domaine important de la
		  transformation de programmes. Nous allons expliquer ce
		  qu'est le d\'ecoupage de programmes, donner un aper{\c c}u
		  rapide de ses diff\'erents aspects et montrer comment
		  Transformers pourrait \^etre utilis\'e comme un outil
		  permettant le d\'ecoupage de programmes.},
  number	= 0825
}

@TechReport{	  queze.08.seminar.transend,
  author	= {Florian Qu\`eze},
  title		= {{Transformers}: toward the end of the pipeline},
  titre		= {{Transformers} : vers la fin du tunnel},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/URLLRDE},
  abstract	= {The goal of the {Transformers} project is to create a C
		  and C++ manipulation framework. Once achieved, it will
		  simplify the creation of transformation or analysis tools
		  for the C++ language. It will also allow experiments with
		  language extensions.

		  {Transformers}' students have been working for years on the
		  project, handing over, each year, the results of their work
		  to the next generation. Lots of tools have been created,
		  each of them solving (or attempting to) a problem that we
		  face when trying to manipulate C++ code. Tens of reports
		  have been written. Some are outdated, but some of them are
		  still a valuable resource.

		  It's now time to take a step back and to have a look at
		  what has been accomplished and what does not work yet in
		  order to decide if and how we want to go forward on this
		  project.},
  resume	= {Le but du projet {Transformers} est de cr\'eer un ensemble
		  d'outils de manipulation de C et C++. Une fois achev\'e, il
		  simplifiera la cr\'eation d'outils de transformation ou
		  d'analyse pour le C++. Il permettra aussi d'exp\'erimenter
		  des extensions du langage.

		  Les \'etudiants du groupe {Transformers} ont travaill\'e
		  pendant des ann\'ees, passant chaque ann\'ee le r\'esultat
		  de leur travail \`a la g\'en\'eration suivante. De nombreux
		  outils ont \'et\'e cr\'e\'es, chacun d'eux r\'esolvant (ou
		  tentant de r\'esoudre) un probl\`eme auquel nous sommes
		  confront\'es en essayant de manipuler du C++. Des dizaines
		  de rapports ont \'et\'e \'ecrits : certains sont
		  obsol\`etes, mais d'autres sont des ressources pr\'ecieuses.

		  Il est maintenant temps de prendre du recul, de regarder le
		  travail accompli et ce qui ne fonctionne pas encore, afin
		  de d\'ecider si et comment nous voulons poursuivre ce projet.},
  urllrde	= {URLLRDE},
  number	= 0836
}

@TechReport{	  raud.08.seminar,
  author	= {C\'edric Raud},
  title		= {{C}entaur: A generic framework simplifying {C++}
		  transformation},
  titre		= {{C}entaur : Une infrastructure g\'en\'erique simplifiant
		  les transformations de {C++}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://lrde.org/cgi-bin/twiki/view/Publications/200807-Seminar-Raud}
		  ,
  urllrde	= {200807-Seminar-Raud},
  abstract	= {The C++ standard grammar was not thought to be easily
		  parsable so its use in the context of program handling can
		  be compared to the complexity of the AST generated by it.
		  The aim of Centaur inside Tranformers is to propose a
		  generic framework allowing to manipulate and digest this
		  AST : program transformations are simplified thanks to an
		  easier access to the parse tree data and its annotations.
		  Thanks to this library, repetitive and error-prone tasks
		  like enumerating a container's elements or the parent
		  classes lookup of a class will be factorized by a function
		  set corresponding to an extensible and modular model.},
  resume	= {La grammaire du standard du C++ n'ayant pas \'et\'e
		  con\c{c}ue pour etre ais\'ement analysable, son utilisation
		  dans le cadre de la manipulation de programme est
		  comparable \`a la complexit\'e de l'AST g\'en\'er\'e par
		  celle-ci. Le r\^ole de Centaur au sein de Transformers est
		  ainsi de fournir une infrastructure g\'en\'erique
		  permettant de manipuler et de synth\'etiser cet AST : les
		  transformations de programmes sont simplifi\'ees gr\`ace a
		  un acc\`es plus ais\'e aux informations contenues dans
		  l'arbre syntaxique et ses annotations. Gr\^ace \`a cette
		  bibliotheque, les t\^aches r\'ep\'etitives et souvent
		  g\'en\'eratrices d'erreurs, comme l'\'enum\'eration des
		  \'el\'ements d'un conteneur ou la recherche des classes
		  parentes d'une classe, seront factoris\'ees par un ensemble
		  de fonctions correspondant \`a un mod\`ele modulaire et extensible.},
  number	= 0823
}

@TechReport{	  roussel.04.seminar,
  author	= {Julien Roussel},
  title		= {\textsc{Transformers}: {C++} type-checking},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2004,
  number	= 0402
}

@TechReport{	  roussel.04.seminar2,
  author	= {Julien Roussel},
  title		= {{C++} type-checking: A study of existing solutions},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2004
}

@TechReport{	  sadegh.08.seminar,
  author	= {Guillaume Sadegh},
  title		= {A Promela front-end for Spot},
  titre		= {Front-end Promela dans Spot},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  abstract	= {Spot is a C++ library for model checking. For
		  verification, Spot uses an input-format which describes a
		  Transition-based Generalized B\"uchi Automata (TGBA).
		  However, this format doesn't seem accessible for users with
		  its poor abstraction and the need for often representing
		  automaton with millions of states. Promela (Process
		  Meta-Language) is a verification modeling language used by
		  the Spin model checker. It lets users to describe a
		  parallel system for verification in a high level
		  programming language. We will present different ways to add
		  a Promela front-end in Spot, which will allow to explore
		  the state-graph on-the-fly, in order to avoid storing all
		  the states.},
  resume	= {Spot est une biblioth\`eque de model checking. Pour
		  v\'erifier des mod\`eles, Spot utilise un format d'entr\'ee
		  repr\'esentant des automates de B\"uchi g\'en\'eralis\'es
		  bas\'es sur les transitions (TGBA). Ce format est peu
		  pratique pour des utilisateurs, par son manque
		  d'abstraction et par la taille des automates \`a
		  repr\'esenter, souvent compos\'es de millions d'\'etats.
		  Promela (Process Meta-Language) est un langage de
		  sp\'ecification de syst\`emes asynchrones, utilis\'e par le
		  model checker Spin. Il permet de repr\'esenter des
		  syst\`emes concurrents dans un langage imp\'eratif de haut
		  niveau. Nous allons pr\'esenter plusieurs approches pour
		  l'ajout d'un front-end Promela dans Spot, qui devront
		  permettre une exploration \`a la vol\'ee du graphe
		  d'\'etats, afin d'\'eviter de conserver en m\'emoire tous les \'etats.},
  url		= {http://publications.lrde.epita.fr/200807-Seminar-Sadegh},
  urllrde	= {200807-Seminar-Sadegh},
  number	= 0817
}

@TechReport{	  sadegh.09.seminar,
  author	= {Guillaume Sadegh},
  title		= {Complementing {B\"uchi} Automata},
  titre		= {La compl\'ementation d'automates de {B\"uchi}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  abstract	= {Model checking is a field of formal verification which
		  aims to automatically test the behavior of a system with
		  the help of logic formulae. Spot is a model checking
		  library which relies on one technique: the
		  automata-theoretic approach. In this approach, both system
		  and formula are expressed with {B\"uchi} automata, which
		  are automata on infinite words. Spot provides several
		  algorithms to deal with these automata, with model checking
		  as objective. However, an algorithm is missing: the
		  complementation of {B\"uchi} automata. Because of its high
		  complexity this algorithm is rarely used in practical, but
		  it does not lack theoretical interests. We will present an
		  implementation of this algorithm in Spot. },
  resume	= {Le model checking est un domaine de la v\'erification
		  formelle permettant de v\'erifier le comportement d'un
		  syst\`eme \`a travers des formules logiques. Spot est une
		  biblioth\`eque de model checking qui repose sur une des
		  techniques du domaine : l'approche automate. Dans cette
		  approche du model checking, le syst\`eme et les formules
		  sont repr\'esent\'es sous forme d'automates acceptant des
		  mots de longueur infinie, et plus particuli\`erement des
		  automates de {B\"uchi}. Spot propose de nombreux
		  algorithmes aux utilisateurs de la biblioth\`eque pour
		  manipuler ce type d'automates, en vue d'applications au
		  model checking. Pourtant, un algorithme est manquant :
		  celui de la compl\'ementation d'automates de {B\"uchi} (qui
		  produit un automate reconnaissant la n\'egation du langage
		  initialement reconnu). Cet algorithme est peu utilis\'e
		  dans la pratique \`a cause de sa forte complexit\'e, mais
		  il ne manque pas d'int\'er\^et du point de vue th\'eorique.
		  Nous pr\'esenterons une impl\'ementation d'un tel algorithme dans Spot.},
  url		= {http://publications.lrde.epita.fr/200906-Seminar-Sadegh},
  urllrde	= {200906-Seminar-Sadegh},
  number	= 0903
}

@TechReport{	  sadegh.10.seminar,
  author	= {Guillaume Sadegh},
  title		= {Complementing {B\"uchi} Automata With Alternating
		  Automata},
  titre		= {La compl\'ementation d'automates de {B\"uchi} \`a travers
		  des automates alternants},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  abstract	= { Model checking is a field of formal verification which
		  aims to automatically test the behavior of a system with
		  the help of temporal logic formulae. Spot is a model
		  checking library which relies on one technique: the
		  automata-theoretic approach. In this approach, both system
		  and formula are expressed with B\"uchi automata, which are
		  automata on infinite words. Spot provides several
		  algorithms to deal with these automata, with model checking
		  as objective. An operation for automata was recently added
		  in Spot : the complementation. Research of algorithms for
		  this operation is still relevant today, since there is
		  still no algorithm reaching the theoretical optimal bound.
		  We will present two recent complementation algorithms
		  implemented in Spot. },
  resume	= {Le model checking est un domaine de la v\'erification
		  formelle, qui permet de v\'erifier le comportement d'un
		  syst\`eme avec l'aide de formules logiques temporelles.
		  Spot est une biblioth\`eque de model checking qui repose
		  sur une des techniques du domaine : l'approche automate.
		  Dans cette approche du model checking, le syst\`eme et les
		  formules sont repr\'esent\'es sous forme d'automates
		  acceptant des mots de longueur infinie, et plus
		  particuli\`erement des automates de B\"uchi. Spot propose
		  de nombreux algorithmes aux utilisateurs de la
		  biblioth\`eque pour manipuler ce type d'automates, en vue
		  d'applications au model checking. Une op\'eration sur ces
		  automates a r\'ecemment \'et\'e ajout\'ee dans Spot : la
		  compl\'ementation. La recherche d'algorithmes effectuant
		  cette op\'eration est toujours d'actualit\'e puisqu'il
		  n'existe toujours pas d'algorithme atteignant les bornes
		  th\'eoriques optimales. Nous pr\'esenterons deux
		  algorithmes r\'ecents de compl\'ementation que nous venons
		  d'ajouter dans Spot, qui se basent sur des automates alternants. },
  url		= {http://publications.lrde.epita.fr/201001-Seminar-Sadegh},
  urllrde	= {201010-Seminar-Sadegh},
  number	= 0915
}

@TechReport{	  seine.08.seminar,
  author	= {Warren Seine},
  titre		= {D\'esambigu\"isation des patrons de type C++ avec les
		  Grammaires Attribu\'ees de Transformers},
  title		= {C++ template disambiguation with {Transformers} Attribute
		  Grammars},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  number	= 0811,
  url		= {http://publications.lrde.epita.fr/200807-Seminar-Seine},
  urllrde	= {200807-Seminar-Seine},
  abstract	= {C++ is a context-sensitive language that can be parsed
		  using a context-free but ambiguous grammar. Disambiguation
		  is then required to select the unique semantically-valid
		  parse tree. Transformers, a framework for C++ program
		  transformation, uses attribute grammars to achieve that
		  stage.

		  One of the hardest ambiguity in the language is related to
		  metaprogramming. In so far as code is generated when
		  templates are instanciated, types are not fully known at
		  the declaration site. Therefore, type-checking is needed to
		  perfectly handle templates, and it poses a real challenge.

		  This report focuses on template disambiguation, detailing
		  the problems and how to resolve it, in order to provide a
		  better platform for source manipulation.},
  resume	= {Malgr\'e sa sensibilit\'e au contexte, le C++ est
		  analysable avec une grammaire hors-contexte mais ambig\"ue.
		  La d\'esambigu\"isation est ensuite n\'ec\'essaire pour
		  s\'electionner le seul arbre syntaxique s\'emantiquement
		  valide. Transformers est une collection d'outils pour la
		  transformation de programmes C++ qui utilise les grammaires
		  attribu\'ees pour r\'ealiser cette \'etape.

		  Une des plus difficiles ambiguit\'es dans le langage
		  concerne la m\'eta-programmation. Puisque du code est
		  g\'en\'er\'e \`a l'instanciation, tous les types ne sont
		  pas n\'ec\'essairement connus \`a la d\'eclaration. La
		  v\'erification des types est donc obligatoire pour traiter
		  totalement le cas des patrons, ce qui pose un v\'eritable
		  d\'efi.

		  Ce rapport se concentre sur la d\'esambigu\"isation des
		  patrons de type et d\'etaille les probl\`emes et leur
		  m\'ethode de r\'esolution, afin de fournir une meilleure
		  plateforme de manipulation de sources.}
}

@TechReport{	  seine.09.seminar,
  author	= {Warren Seine},
  title		= {An implementation of the {C++} container library with
		  {SCOOL}},
  titre		= {Une impl\'ementation des conteneurs C++ avec SCOOL},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2009,
  number	= 0904,
  abstract	= {SCOOL is a domain-specific language (DSL) designed to make
		  high-level C++ development easier. Based on SCOOP, a
		  paradigm mixing generic and object-oriented programming, it
		  features static resolution of member function calls and
		  powerful concept checking.

		  Previously, a standard container library had been made in
		  pure C++ using SCOOP. However, this implementation required
		  high control of the C++ techniques of SCOOP. With SCOOL, we
		  can achieve this by leaving the hard work to the C++
		  translator.

		  Focusing on the development of the library with SCOOL and
		  the essential changes to the language and its compiler, we
		  will compare the native and DSL solutions and assess that
		  SCOOL is well-fitted for generic application prototyping.},
  resume	= {SCOOL est un langage d\'edi\'e (DSL) destin\'e \`a
		  faciliter le d\'eveloppement C++ de haut-niveau. Fond\'e
		  sur le paradigme SCOOP m\'elangeant programmation
		  g\'en\'erique et orient\'ee-objet, il se d\'emarque par une
		  r\'esolution statique des appels de fonctions membres et un
		  syst\`eme de concepts puissant.

		  Pr\'ec\'edemment, une biblioth\`eque de conteneurs
		  standards a \'et\'e r\'ealis\'ee en C++ gr\^ace \`a SCOOP.
		  Cette impl\'ementation demandait cependant une forte
		  ma\^itrise des m\'ecanismes de SCOOP. Avec SCOOL, nous
		  pouvons y arriver sans se pr\'eoccuper des d\'etails,
		  laiss\'es au traducteur C++.

		  En se concentrant sur le d\'eveloppement de la
		  biblioth\`eque en SCOOL et sur les changements
		  n\'ecessaires au langage et \`a son compilateur, nous
		  comparerons les solutions originales et \`a base de DSL et
		  d\'eterminerons si SCOOL est adapt\'e au prototypage d'applications g\'en\'eriques.},
  url		= {http://publications.lrde.epita.fr/200905-Seminar-Seine},
  urllrde	= {200905-Seminar-Seine}
}

@TechReport{	  seine.10.seminar,
  author	= {Warren Seine},
  title		= {Integrating modern parallel techniques in the Tiger
		  compiler},
  titre		= {Int\'egration de techniques de parall\'elisation dans le
		  compilateur Tiger},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2010,
  number	= 0911,
  abstract	= {Tiger is a language designed as a reference for
		  pedagogical compiler writing. Our C++ implementation of a
		  Tiger compiler takes advantage of well-established
		  practices in program transformation tools.

		  The multi-core era has made parallelization a requirement
		  in any computer science curriculum. As a support for
		  teaching, our compiler has to evolve and make use of modern
		  parallel techniques.

		  This report introduces a solution to distribute work in a
		  task-based concurrency model using Intel Threading Building
		  Blocks (TBB) to decouple the programming from hardware
		  specificities.},
  resume	= {Tiger est un langage utilis\'e \`a des fins p\'edagogiques
		  dans l'\'etude des compilateurs. \'Ecrite en C++, notre
		  impl\'ementation d'un compilateur Tiger profite de
		  techniques \'eprouv\'ees dans la transformation de
		  programmes.

		  L'\`ere du multi-c\oe{}ur a rendu la parall\'elisation
		  indispensable dans le cursus d'un \'etudiant en
		  informatique. Utilis\'e comme support de cours, notre
		  compilateur doit \'evoluer et tirer profit des nouvelles
		  techniques de parall\'elisme.

		  Ce rapport pr\'esente une solution pour distribuer le
		  travail au sein d'un mod\`ele de programmation concurrente
		  par t\^ache. Nous utiliserons Intel Threading Building
		  Blocks pour nous d\'etacher des probl\'ematiques mat\'erielles.},
  url		= {http://publications.lrde.epita.fr/201001-Seminar-Seine},
  urllrde	= {201001-Seminar-Seine}
}

@TechReport{	  senta.11.seminar,
  author	= {Laurent Senta},
  title		= {{Climb: Weighted Neighborhood Implementation}},
  titre		= {{Climb: Impl\'ementation de voisinage pond\'er\'es}},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2011,
  url		= {http://publications.lrde.epita.fr/201107-Seminar-Senta},
  urllrde	= {201107-Seminar-Senta},
  abstract	= {Climb is a generic image processing library developed in
		  Lisp. Neighborhoods are represented as site-set to allow
		  generic manipulation over multiple pictures type. Along
		  these concepts, a study of weighted neighborhood
		  representation is done, showing how we can extend the
		  concept of writing algorithms once and running them over
		  different parameters type. Three implementations are
		  proposed, described and compared on both genericity and
		  expressivity.},
  resume	= {Climb est une biblioth\`eque de traitement d'images
		  g\'en\'erique d\'evelopp\'ee en Lisp. Les voisinages sont
		  represent\'es sous la forme d'ensemble de sites (site-set)
		  pour permettre des manipulations g\'en\'eriques sur de
		  multiples types d'images. En parall\`ele de ce concept, une
		  \'etude des voisinages pond\'er\'es est effectu\'ee,
		  expliquant diff\'erents moyens d'\'etendre le concept d'une
		  \'ecriture unique des algorithmes pour les ex\'ecuter sur
		  diff\'erents types de param\`etres. Trois impl\'ementations
		  sont propos\'ees, d\'ecrites et compar\'ees au niveau de
		  leur g\'en\'ericit\'e et de leur expressivit\'e.},
  number	= 1106
}

@TechReport{	  sigoure.06.seminar,
  oldkeys	= {sigoure.06.seminar.xrm},
  author	= {Beno\^it Sigoure},
  title		= {{eX}tended {R}eactive {M}odules},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2006,
  url		= {http://publications.lrde.epita.fr/200607-Seminar-Sigoure},
  urllrde	= {200607-Seminar-Sigoure},
  abstract	= {Reactive Modules is a formal model used to represent
		  synchronous and asynchronous components of a system. PRISM
		  is a widely used probabilistic model-checker. It introduced
		  the PRISM language, highly based on the Reactive Modules
		  formalism. This language quickly reaches its limit when it
		  comes to large models.

		  eXtended Reactive Modules (XRM) is an extension of the
		  PRISM language. It comes with a compiler that translate XRM
		  modules in PRISM modules, thus providing a comprehensive
		  and reliable solution for people willing to write large
		  models.},
  resume	= {Reactive Modules est un mod\`ele formel utilis\'e pour
		  d\'ecrire les \'el\'ements synchrones et asynchrones d'un
		  syst\`eme. PRISM est un outil de model-checking
		  probabiliste. Il a introduit le langage PRISM, grandement
		  bas\'e sur le formalisme de Reactive Modules. Ce langage
		  atteinte vite ses limites lorsqu'il s'agit de d\'ecrire des
		  mod\`eles cons\'equants.

		  eXtended Reactive Modules est une extension du langage
		  PRISM. Il est fournit avec un compilateur qui traduit les
		  modules XRM en modules PRISM, fournissant ainsi une
		  solution fiable et compl\`ete pour les gens ayant besoin de
		  d\'ecrire des syst\`emes cons\'equants.},
  number	= 0620
}

@TechReport{	  sigoure.07.seminar,
  author	= {Beno\^it Sigoure and Quentin Hocquet},
  title		= {{revCPP} A reversible {C++} preprocessor},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200801-Seminar-Hocquet},
  urllrde	= {200801-Seminar-Hocquet}
}

@TechReport{	  sigoure.08.seminar,
  author	= {Beno\^it Sigoure},
  title		= {Run-Time Concrete-Syntax Program-Transformation in General
		  Purpose Languages},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200801-Seminar-Sigoure-CC}
		  ,
  urllrde	= {200801-Seminar-Sigoure-CC},
  abstract	= {Program transformation in general purpose languages such
		  as \Cxx is tedious because it requires the \acf{ast} of the
		  transformed program to be manipulated in abstract syntax
		  (that is, in the host language, \Cxx here). The code to
		  write is unwieldy and costly to maintain.

		  This object of the seminar is to present the implementation
		  of new concrete syntax program transformation techniques
		  (that is, using directly the language of the transformed
		  program) in a standard \Cxx environment. Our approach uses
		  the parser at run-time to apply dynamic transformation
		  rules. A Tiger compiler will be used to support the
		  presentation.},
  resume	= {La transformation de programmes dans des langages
		  g\'en\'eralistes tels que le \Cxx est fastidieuse car elle
		  n\'ecessite de manipuler l'\acf{ast} du programme transform
		  en syntaxe abstraite (c'est-\`a-dire dans le langage
		  h\^ote, ici le \Cxx). Le code \`a \'ecrire est lourd et
		  co\^uteux maintenir.

		  Le but de ce s\'eminaire est de pr\'esenter la mise en
		  \oe{}uvre de nouvelles techniques de transformation de
		  programmes en syntaxe concr\`ete (c'est-\`a-dire utilisant
		  directement le langage du programme transform\'e) dans un
		  environnement \Cxx standard. Notre approche utilise
		  l'analyseur syntaxique l'ex\'ecution pour appliquer des
		  r\`egles de transformation dynamiques. Un compilateur de
		  Tiger servira de support \`a la pr\'esentation.}
}

@TechReport{	  terrones.05.seminar,
  oldkeys	= {terrones.exp-to-aut.05.seminar},
  author	= { Florent Terrones },
  title		= { From an expression to the original automaton },
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2005,
  urllrde	= {20050622-Seminar-Terrones-DerivedTerms-Slides},
  number	= 0507
}

@TechReport{	  thivolle.05.seminar,
  oldkeys	= {thivolle.canvas-olena.05.seminar},
  author	= {Damien Thivolle},
  title		= {Canvas in {O}lena},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2005,
  urllrde	= {200506-Seminar-Thivolle},
  number	= 0502
}

@TechReport{	  van-noppen.07.seminar,
  oldkeys	= {van-noppen.07.seminar.scool},
  author	= {Maxime van Noppen},
  title		= {{SCOOL}: object orientation of a static language},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2007,
  url		= {http://publications.lrde.epita.fr/200706-Seminar-van-Noppen}
		  ,
  urllrde	= {200706-Seminar-van-Noppen}
}

@TechReport{	  van-noppen.08.seminar,
  author	= {Maxime van Noppen},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200806-Seminar-VanNoppen}
		  ,
  number	= 0816,
  urllrde	= {200806-Seminar-VanNoppen},
  titre		= {{SCOOL}: Programmation g\'en\'erique et concepts},
  title		= {{SCOOL}: Concept-Oriented Programming},
  resume	= {\textsc{Scool} est un langage statique orient\'e objet qui
		  a \'et\'e cr\'e\'e afin de pouvoir utiliser toute la
		  puissance du \Cxx statique de mani\`ere plus ais\'ee
		  gr\^ace \`a une syntaxe plus expressive et agr\'eable. Il
		  n'a pas pour but d'\^etre directement compil\'e mais
		  d'\^etre traduit en \Cxx. Cette ann\'ee le travail rev\^et
		  une importance particuli\`ere. En effet, \textsc{Scool} est
		  d\'evelopp\'e en \'etroite collaboration avec l'\'equipe de
		  d\'eveloppement de la biblioth\`eque de traitement d'images
		  \textsc{Milena} de la plate-forme \textsc{Olena} ; l'an
		  pass\'e a \'et\'e pour elle le cadre de grands changements
		  internes. Un des axes majeurs du d\'eveloppement de
		  \textsc{Scool} va donc \^etre de s'adapter aux nouveaux
		  paradigmes et aux nouveaux besoins de la biblioth\`eque. Le
		  second axe essentiel de travail est la poursuite du
		  d\'eveloppement du langage. Cette ann\'ee le travail va
		  \^etre concentr\'e sur la programmation par concepts qui
		  est une approche permettant de formaliser facilement des
		  contraintes sur la programmation g\'en\'erique.},
  abstract	= {\textsc{Scool} is a static object-oriented language. It
		  has been created to help one to take advantage of all the
		  power of static \Cxx thanks to a more expressive syntax. It
		  is not directly compiled but is translated into \Cxx. This
		  year was quite important for the project. Indeed, there are
		  tight links between \textsc{Scool}'s development and the
		  generic image processing library \textsc{Milena} from the
		  \textsc{Olena} platform. As some big changes occured in the
		  library, work needs to be done to adapt the language to its
		  new paradigms and to its new needs. Work also needs to be
		  done to continue the implementation of the different
		  features of \textsc{Scool}. This year the work will be
		  focused on concept-oriented programming. This allows one to
		  easily express constraints on generic programming.}
}

@TechReport{	  van-noppen.09.seminar,
  author	= {Maxime van Noppen},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  url		= {http://publications.lrde.epita.fr/200901-Seminar-VanNoppen}
		  ,
  urllrde	= {200901-Seminar-VanNoppen},
  titre		= {{SCOOL}: Programmation g\'en\'erique},
  title		= {{SCOOL}: Generic programming},
  resume	= {Le \Cxx est un langage puissant pour \'ecrire des
		  biblioth\`eques g\'en\'eriques et performantes. Cependant,
		  dans certains domaines l'utilisation de l'orient\'e objet
		  usuel peut poser des probl\`emes de performances, comme
		  dans celui des biblioth\`eques de calcul scientifique dans
		  lesquelles de grands ensembles de donn\'ees parcourus par
		  des algorithmes g\'en\'eriques. La solution propos\'ee est
		  la combinaison de la programmation orient\'ee objet
		  classique et de la programmation \emph{statique} qui est en
		  fait de la meta-programmation utilisant intensivement les
		  \emph{templates} du \Cxx. Ceci a l'avantage de remplacer le
		  co\^ut \`a l'\'execution de l'orient\'e objet d\^u \`a la
		  r\'esolution des m\'ethodes virtuelles par un co\^ut `a la
		  compilation. Cependant, cela engendre souvent du code
		  verbeux, difficile \`a \'ecrire et \`a maintenir. Malgr\'e
		  sa puissance, le \Cxx ne poss\`ede pas d'abstractions
		  statiques de haut niveau ce qui encombre la s\'emantique du
		  code avec des d\'etails d'impl\'ementation. Nous vous
		  pr\'esentons \textsc{Scool}, un langage statique fusionnant
		  l'orient\'e objet et la programmation g\'en\'erique dans le
		  but d'\'exploiter toute la puissance du \Cxx statique
		  gr\^ace \`a une syntaxe plus expressive. De plus, toutes
		  les r\'esolutions de m\'ethodes se feront statiquement
		  gr\^ace au fait que le type exact (dynamique) de chaque
		  objet est connu \`a la compilation. Le but de
		  \textsc{Scool} \'etant d'apporter toute la puissance de
		  l'orient\'e objet statique au \Cxx, il ne sera pas
		  directement compil\'e mais traduit en \Cxx correctement
		  format\'e. Le d\'eveloppement du traducteur a soulev\'e les
		  probl\`emes classiques du domaine des DSL comme la
		  strat\'egie de parcours de l'arbre de syntaxe. Nous
		  proposons une solution originale bas\'ee sur la plateforme
		  de transformation de programme Stratego/XT avec des
		  applications \`a Milena, la biblioth\`eque g\'en\'erique et performante de traitement d'image de la plateforme Olena.},
  abstract	= {\Cxx has proved to be a powerful language to write generic
		  and efficient libraries. However using classical \ac{oo}
		  \Cxx may not fulfill the efficiency criterion sought in
		  some domains, e.g. when building scientific libraries,
		  where large data sets have to be processed through generic
		  algorithms. A solution consists in combining the power of
		  \acl{oop} and \emph{static} programming--- which is in fact
		  meta-code expressed thanks to \Cxx template constructs.
		  This has the advantage to replace the \ac{oo} run-time
		  overhead (due to virtual method dispatch) by compile-time
		  computations. However, such an approach relies on code that
		  is verbose, hard to write and to maintain. Though powerful,
		  \Cxx lacks high-level static features, and thus clutters
		  the semantics of static constructs with unrelated code. We
		  present \textsc{Scool}, a static language mixing \ac{oo}
		  and \ac{gp} that has been created to take advantage of all
		  the power of static \Cxx thanks to a more expressive syntax
		  and high-level constructs, without the drawbacks of plain
		  \Cxx. As a full-fledged static OOP language, \textsc{Scool}
		  provides polymorphic methods (i.e., inclusion
		  polymorphism), with the notable difference that every
		  polymorphic call is statically-resolved: the design of
		  \textsc{Scool} is based on the property that the exact
		  (dynamic) type of every object is known at compile-time. As
		  the aim of \textsc{Scool} is to bring all the power of
		  static \acl{oop} to \Cxx, it is not directly compiled but
		  translated into human-readable \Cxx. The development of the
		  translator raised classical problems found in \acp{dsl}
		  like traversal strategies of the abstract syntax tree. We
		  propose an original solution based on the Stratego/XT
		  program transformation framework, and some applications on
		  Milena, a generic and efficient \Cxx library from the Olena
		  image processing platform.}
}

@TechReport{	  vasseur.04.seminar,
  title		= {Semantics driven disambiguation: a comparison of different
		  approaches},
  author	= {Cl\'ement Vasseur},
  institution	= {LRDE},
  year		= 2004,
  urllrde	= {20041201-Seminar-Vasseur-Disambiguation-Report}
}

@TechReport{	  vigouroux.08.seminar,
  author	= {Caroline Vigouroux},
  title		= {Color types in {M}ilena},
  titre		= {Les types de couleur dans Milena},
  institution	= {EPITA Research and Development Laboratory (LRDE)},
  year		= 2008,
  urllrde	= {200807-Seminar-Vigouroux},
  abstract	= {The Olena project provides a generic library for image
		  processing, Milena. We want this library to feature many
		  value types so that the user can always choose the relevant
		  types for his application. For instance, we provide many
		  grey-level types, many color types, etc.

		  This seminar focuses on how we implement color types in
		  Milena. There are different color spaces (RGB, HSI, and so
		  on) and several possible encodings for the same color space
		  (rgb\_3x8, rgb\_f, etc.). One objective of ours is to make
		  things easy for the user. In particular, we want the user
		  to handle color values without being concerned of internal
		  mechanisms. For instance, in conversion formulas, we do not
		  want to see the details of implementation (division by
		  255).},
  resume	= {Le projet Olena fournit une biblioth\`eque g\'en\'erique
		  pour le traitement d'images, Milena. Nous voulons que cette
		  biblioth\`eque procure de nombreux types de valeur tels que
		  l'utilisateur puisse toujours choisir le type adapt\'e pour
		  son application. Par exemple, nous fournissons de nombreux
		  encodages en niveau de gris, de nombreux espaces de
		  couleur, etc.

		  Nous pr\'esentons la mani\`ere dont nous mettons en
		  \oe{}uvre les types de couleurs dans Milena. Il existe
		  diff\'erents espaces de couleur (RGB, HSI, et bien
		  d'autres) et il existe plusieurs encodages possibles pour
		  les m\^emes espaces de couleur (rgb\_3x8, rgb\_f, etc.).
		  Nous voulons rendre les choses plus faciles pour
		  l'utilisateur. Donc, notre objectif est de rendre possible
		  l'utilisation des espaces de couleur sans se soucier des
		  m\'ecanismes internes. Par exemple, dans les formules de
		  conversion, on ne veut pas faire appara\^itre les d\'etails
		  d'impl\'ementation (division par 255).}
}
